mime version server cern date tuesday jan gmt content type text html content length last modified wednesday aug gmt theory refinement theory refinement view paper click open book image combining symbolic connectionist learning methods refine certainty factor rule bases j jeffrey mahoney ph d thesis department computer sciences university texas austin may research describes system rapture designed revise rule bases expressed certainty factor format recent studies shown learning facilitated biased domain specific expertise also shown many real world domains require form probabilistic uncertain reasoning order successfully represent target concepts rapture designed take advantage results beginning set certainty factor rules along accurately labelled training examples rapture makes use symbolic connectionist learning techniques revising rules order correctly classify training examples modified version backpropagation used adjust certainty factors rules id information gain heuristic used add new rules upstart algorithm used create new hidden terms rule base results refining four real world rule bases presented demonstrate effectiveness combined approach two rule bases designed identify particular areas strands dna one identifying infectious diseases fourth attempts diagnose soybean diseases results rapture compared backpropagation c kbann learning systems rapture generally produces sets rules accurate systems often creating smaller sets rules using less training time refinement bayesian networks combining connectionist symbolic techniques sowmya ramanchandran ph d proposal department computer sciences university texas austin bayesian networks provide mathematically sound formalism representing reasoning uncertain knowledge widely used however acquiring capturing knowledge framework difficult growing interest formulating techniques learning bayesian networks inductively problem learning bayesian network given complete data explored depth problem learning networks unobserved causes still open proposal view problem perspective theory revision present novel approach adapts techniques developed revising theories symbolic connectionist representations thus assume learner given initial approximate network usually obtained expert technique inductively revises network fit data better proposed system two components one component revises parameters bayesian network known structure component revises structure network component parameter revision maps given bayesian network multi layer feedforward neural network parameters mapped weights neural network uses standard backpropagation techniques learn weights structure revision component uses qualitative analysis suggest revisions network fails predict data accurately first component implemented present results experiments real world classification problems show technique effective also discuss proposed structure revision algorithm plans experiments evaluate system well extensions system novel application theory refinement student modeling paul baffes raymond j mooney proceedings thirteenth national conference aritificial intelligence pp portland august aaai theory refinement systems developed machine learning automatically modify knowledge base render consistent set classified training examples illustrate novel application techniques problem constructing student model intelligent tutoring system approach implemented authoring system called assert uses theory refinement introduce errors initially correct knowledge base models incorrect student behavior efficacy approach demonstrated evaluating tutor developed assert students tested classification task covering concepts introductory course c programming language system produced reasonably accurate models students received feedback based models performed significantly better post test students received simple reteaching refinement based student modeling automated bug library construction paul baffes raymond mooney journal artificial intelligence education pp critical component model based intelligent tutoring sytems mechanism capturing conceptual state student enables system tailor feedback suit individual strengths weaknesses useful modeling technique must practical sense models easy construct effective sense using model actually impacts student learning research presents new student modeling technique automatically capture novel student errors using correct domain knowledge automatically compile trends across multiple student models approach implemented computer program assert using machine learning technique called theory refinement method automatically revising knowledge base consistent set examples using knowledge base correctly defines domain examples student behavior domain assert models student errors collecting refinements correct knowledege base necessary account student behavior efficacy approach demonstrated evaluating assert using students tested classification task covering concepts introductory course c programming language students received feedback based models automatically generated assert performed significantly better post test students received simple teaching revising bayesian network parameters using backpropagation sowmya ramachandran raymond j mooney proceedings international conference neural networks icnn special session knowledge based artificial neural networks washington dc june problem learning bayesian networks hidden variables known hard problem even simpler task learning conditional probabilities bayesian network hidden variables hard paper present approach learns conditional probabilities bayesian network hidden variables transforming multi layer feedforward neural network ann conditional probabilities mapped onto weights ann learned using standard backpropagation techniques avoid problem exponentially large anns focus bayesian networks noisy noisy nodes experiments real world classification problems demonstrate effectiveness technique automatic student modeling bug library construction using theory refinement paul baffes ph d thesis department computer sciences university texas austin december history computers education characterized continuing effort construct intelligent tutorial programs adapt individual needs student one one setting critical component intelligent tutorials mechanism modeling conceptual state student system able tailor feedback suit individual strengths weaknesses primary contribution research new student modeling technique automatically capture novel student errors using correct domain knowledge automatically compile trends across multiple student models bug libraries approach implemented computer program assert using machine learning technique called theory refinement method automatically revising knowledge base consistent set examples using knowledge base correctly defines domain examples student behavior domain assert models student errors collecting refinements correct knowledge base necessary account student behavior efficacy approach demonstrated evaluating assert using students tested classification task using concepts introductory course c programming language students received feedback based models automatically generated assert performed significantly better post test students received simple reteaching comparing methods refining certainty factor rule bases j jeffrey mahoney raymond j mooney proceedings eleventh international workshop machine learning pp rutgers nj july ml paper compares two methods refining uncertain knowledge bases using propositional certainty factor rules first method implemented rapture system employs neural network training refine certainties existing rules uses symbolic technique add new rules second method based one used kbann system initially adds complete set potential new rules low certainty allows neural network training filter adjust rules experimental results indicate former method results significantly faster training produces much simpler refined rule bases slightly greater accuracy modifying network architectures certainty factor rule base revision j jeffrey mahoney raymond j mooney proceedings international symposium integrating knowledge neural heuristics pp pensacola fl may isiknh paper describes rapture system revising probabilistic rule bases converts symbolic rules connectionist network trained via connectionist techniques uses modified version backpropagation refine certainty factors rule base uses id information gain heuristic quinlan add new rules work currently way finding improved techniques modifying network architectures include adding hidden units using upstart algorithm frean case made via comparison fully connected connectionist techniques keeping rule base close original possible adding new input units needed extending theory refinement m n rules paul baffes raymond j mooney informatica pp recent years machine learning research started addressing problem known theory refinement goal theory refinement learner modify incomplete incorrect rule base representing domain theory make consistent set input training examples paper presents major revision either propositional theory refinement system two issues discussed first show run time efficiency greatly improved changing exhaustive scheme computing repairs iterative greedy method second show extend either refine mofn rules resulting algorithm neither new either order magnitude faster produces significantly accurate results theories fit mofn format demonstrate advantages neither present experimental results two real world domains learning model students using theory refinement detect misconceptions paul baffes ph d proposal department computer sciences university texas austin new student modeling system called assert described uses domain independent learning algorithms model unique student errors automatically construct bug libraries assert consists two learning phases first application theory refinement techniques constructing student models correct theory domain tutored second learning cycle automatically constructs bug library extracting common refinements multiple student models used bias future modeling efforts initial experimental data presented suggests assert effective modeling system induction techniques previously explored student modeling automatic bug library construction significantly enhances subsequent modeling efforts symbolic revision theories m n rules paul baffes raymond j mooney proceedings thirteenth international joint conference artificial intelligence pp chambery france ijcai paper presents major revision either propositional theory refinement system two issues discussed first show run time efficiency greatly improved changing exhaustive scheme computing repairs iterative greedy method second show extend either refine m n rules resulting algorithm neither new either order magnitude faster produces significantly accurate results theories fit m n format demonstrate advantages neither present preliminary experimental results comparing either various systems refining dna promoter domain theory combining connectionist symbolic learning refine certainty factor rule bases j jeffrey mahoney raymond j mooney connection science pp special issue architectures integrating neural symbolic processing paper describes rapture system revising probabilistic knowledge bases combines connectionist symbolic learning methods rapture uses modified version backpropagation refine certainty factors mycin style rule base uses id information gain heuristic add new rules results refining three actual expert knowledge bases demonstrate combined approach generally performs better previous methods refinement first order horn clause domain theories bradley l richards raymond j mooney machine learning pp knowledge acquisition difficult time consuming task error prone human activity task automatically improving existing knowledge base using learning methods addressed new class systems performing theory refinement recently systems limited propositional theories paper presents system forte first order revision theories examples refining first order horn clause theories moving first order representation opens many new problem areas logic program debugging qualitative modelling beyond reach propositional systems forte uses hill climbing approach revise theories identifies possible errors theory calls library operators develop possible revisions best revision implemented process repeats revisions possible operators drawn variety sources including propositional theory refinement first order induction inverse resolution forte tested several domains including logic programming qualitative modelling combining symbolic neural learning revise probabilistic theories j jeffrey mahoney raymond j mooney proceedings machine learning workshop integrated learning real domains aberdeen scotland july paper describes rapture system revising probabilistic theories combines symbolic neural network learning methods rapture uses modified version backpropagation refine certainty factors mycin style rule base uses id information gain heuristic add new rules results two real world domains demonstrate combined approach performs well better previous methods using theory revision model students acquire stereotypical errors paul baffes raymond j mooney proceedings fourteenth annual conference cognitive science society pp bloomington july student modeling identified important component long term development intelligent computer aided instruction icai systems two basic approaches evolved model student misconceptions one uses static predefined library user bugs contains misconceptions modeled system uses induction learn student misconceptions scratch present third approach uses machine learning technique called theory revision using theory revision allows system automatically construct bug library use modeling retaining flexibility address novel errors preliminary pac analysis theory revision raymond j mooney march computational learning theory natural learning systems vol petsche judd hanson eds mit press pp paper presents preliminary analysis sample complexity theory revision within framework pac probably approximately correct learnability theory formalizing notion initial theory close correct theory show sample complexity optimal propositional horn clause theory revision algorithm o ln delta d ln d n epsilon d em syntactic distance initial correct theories size initial theory n number observable features epsilon delta standard pac error probability bounds paper also discusses problems raised computational complexity theory revision automated debugging logic programs via theory revision raymond j mooney bradley l richards proceedings second international workshop inductive logic programming tokyo japan june paper presents results using theory revision system automatically debug logic programs forte recently developed system revising function free horn clause theories given theory set training examples performs hill climbing search attempt minimally modify theory correctly classify examples forte makes use methods propositional theory revision horn clause induction foil inverse resolution system successfully used debug logic programs written undergraduate students programming languages course batch versus incremental theory refinement raymond j mooney proceedings aaai spring symposium knowledge assimilation standford ca march existing theory refinement systems incremental however theory refinement system whose input output theories compatible used incrementally assimilate data evolving theory done continually feeding revised theory back input theory incremental batch approach system assimilates batch examples step seems appropriate existing theory revision systems experimental results either theory refinement system demonstrate approach frequently increases efficiency without significantly decreasing accuracy simplicity resulting theory however system produces bad initial changes theory based small amount data bad revisions snowball result overall decrease performance multistrategy approach theory refinement raymond j mooney dirk ourston machine learning multistrategy approach vol iv r michalski g teccuci eds pp morgan kaufman san mateo ca chapter describes multistrategy system employs independent modules deductive abductive inductive reasoning revise arbitrarily incorrect propositional horn clause domain theory fit set preclassified training instances combining diverse methods either able handle wider range imperfect theories theory revision systems guaranteeing revised theory consistent training data either successfully revised two actual expert theories one molecular biology one plant pathology results confirm hypothesis using multistrategy system learn theory data gives better results using either theory data alone theory refinement combining analytical empirical methods dirk ourston raymond j mooney artificial intelligence pp article describes comprehensive approach automatic theory revision given imperfect theory approach combines explanation attempts incorrectly classified examples order identify failing portions theory theory fault correlated subsets examples used inductively generate correction corrections focused tend preserve structure original theory system starts approximate domain theory general fewer training examples required attain given level performance classification accuracy compared purely empirical system approach applies classification systems employing propositional horn clause theory system tested variety application domains results presented problems domains molecular biology plant disease diagnosis improving shared rules multiple category domain theories dirk ourston raymond j mooney proceedings eighth international machine learning workshop pp evanston il june paper presents approach improving classification performance multiple category theory correcting intermediate rules shared among categories using technique performance theory one category improved training entirely different category examples technique presented experimental results given constructive induction theory refinement raymond j mooney dirk ourston proceedings eighth international machine learning workshop pp evanston il june paper presents constructive induction techniques recently added either theory refinement system additions allow either handle arbitrary gaps top middle bottom incomplete domain theory intermediate concept utilization employs existing rules theory derive higher level features use induction intermediate concept creation employs inverse resolution introduce new intermediate concepts order fill gaps theory span multiple levels revisions allow either make use imperfect domain theories ways typical previous work constructive induction theory refinement result either able handle wider range theory imperfections existing theory refinement system theory refinement noisy data raymond j mooney dirk ourston technical report ai artificial intelligence lab university texas austin march paper presents method revising approximate domain theory based noisy data basic idea avoid making changes theory account small amount data method implemented either propositional horn clause theory revision system paper presents empirical results artificially corrupted data show method successfully prevents fitting words data noisy performance novel test data considerably better revising theory completely fit data data noisy noise processing causes significant degradation performance finally noise processing increases efficiency decreases complexity resulting theory estlin cs utexas edu