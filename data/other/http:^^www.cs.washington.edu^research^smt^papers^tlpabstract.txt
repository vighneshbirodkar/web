date tue dec gmt server ncsa content type text html converting thread level parallelism instruction level parallelism via simultaneous multithreading converting thread level parallelism instruction level parallelism via simultaneous multithreading jack l lo susan j eggers joel emer henry m levy rebecca l stamm dean m tullsen achieve high performance contemporary computer systems rely two forms parallelism instruction level parallelism ilp thread level parallelism tlp wide issue superscalar processors exploit ilp executing multiple instruction signel program single cycle multiprocessors mp exploit tlp executing different threads parallel different processors unfortunately parallel processing styles statically partition processor resources thus preventing adapting dynamically changing levels tlp ilp program insufficient tlp processors mp idle insufficient ilp multiple issue hardware superscalar wasted paper explores parallel processing alternative architecture simultaneous multithreading smt allows multiple threads compete share processor resources every cycle compelling reason running parallel applications smt processor ability use thread level parallelism instruction level parallelism interchangeably permitting multiple threads share processor functional units simultaneously processor use ilp tlp tolerate variations parallelism program single thread smt processor resources dedicated thread tlp exists parallelism compensate lack per thread ilp work examine two alternative chip parallel architectures enabled greatly increased chip densities expected near future compare smt small scale chip multiprocessors mp ability exploit ilp tlp first identify hardware bottlenecks prevent multiprocessors efficiently exploiting ilp show dynamic resource sharing smt avoids inefficiencies benefits able run threads single processor use tlp especially advantageous per thread ilp limited ease adding additional thread contexts smt relative addition additional processors mp allows simultaneous multithreading expose parallelism increasing processor utilization attaining average speedup versus four processor single chip multiprocessor comparable execution resources also assess memory hierarchy affected use additional thread level parallelism show inter thread interference increased memory requirements small impacts total program performance inhibit significant program speedups submitted publication july get postscript file click jlo cs washington edu