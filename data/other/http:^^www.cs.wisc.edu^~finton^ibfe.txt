date mon nov gmt server ncsa content type text html last modified tue apr gmt content length importance based feature extraction outline main idea example real life neural net example gaussian detector nodes new importance based feature extraction main idea suppose autonomous agent feature detectors identify state uses reinforcement learning learn succeed environment importance based feature extraction aims tune agent feature detectors sensitive states agent choice action critical agent action state little bearing agent future success say state unimportant define important state one different predictions reinforcement taking different actions terms q learning means important state one different actions different q values important states necessarily frequently seen frequency based feature extraction misled frequently occurring red herring states may miss states represent rare opportunities example agent frequently finds particular state almost action equally good frequency based feature tuning would cluster detectors around state however detectors little use agent choice action state little bearing future reinforcement agent may find rarely seen state choice action critical future success state important though infrequent course view based assumption agent task act way optimizes reinforcement regardless understanding aspects world bearing strategy selection furthermore important states need associated extreme reinforcement values example may state agent fail matter action takes therefore state strongly associated failure likely extremely negative reinforcement values detecting state helpful agent state nothing prevent failure agent would better using detectors identify state made critical mistake would state correct action might led success instead failure q values state might great absolute magnitude associated state agent always fails state agent always succeeds since actions state lead success failure greater span q values associated actions makes important state example real life cognitive economy one principles use cope daily life people tend use broad classifications whenever possible allows apply information learned samples large collection objects avoid re learn handle new individual object kind stereotyping use classifications relate goals feedback receive goals require us respond particular features individual need learn recognize features make individual special case example consider concept snow concept snow whether pack snowball wet snow fluffy snow otherwise snow something pretty piles requires get shovel skiers talk varieties snow distinctions relevant different kinds snow different effects skiing may remember varieties snow skier friends spoken necessarily comment memory likely due fact ski derive benefit knowing distinctions supposedly eskimos words many different kinds snow someone lived whole life close equator snow might simply snow form white precipitation ve never seen case alloting cognitive resources distinctions relate goals example importance based feature extraction since tuning feature detectors respond features make difference things otherwise falling back broad stereotypes neural net example gaussian detector nodes common architecture reinforcement learning agent feed forward connectionist network inputs layer hidden nodes output layer nodes control action selection think hidden nodes feature detectors provide distributed representation current system state importance based feature extraction attempts tune feature detectors according importance selecting agent actions detector considered important links outputs different weights weights detector would contribute impulse competing output nodes thus would influence agent choice action since link weights used calculate q values detector sizable spread weights outgoing links represents state different actions different expectations reinforcement words detector valuable detects state agent choice action strongly affect agent liklihood success system gaussian detector nodes importance based feature extraction tunes centers order maximize detector estimate importance found convenient define importance detector variance weights links output nodes however alternative definitions certainly possible new importance based feature extraction reinforcement learning problems sparseness feedback increases difficulty feature extraction importance based feature extraction addresses problem relying bottom feature extraction examples general approach include use bottom clustering methods kohonen self organized map chapman kaelbling use relevance criterion statistical approaches built around principal component analysis bottom clustering methods based frequency states kohonen self organized map related clustering methods attempt distribute feature detectors according probability density function states seen agent contrast importance based feature extraction recognizes autonomous agent important states necessarily frequent noted agent needs detect commonly seen states important states states matter terms action decisions agent must make self organized map designed different type problem modelling feature domain producing brain like mapping inputs common features reinforcement topological structure feature space important control task frequency based approach blind toward reinforcement reinforcement makes states important others agent chapman kaelbling concept relevance biases feature extraction toward detection features associated extreme reinforcement values discussed extreme reinforcement values necessarily indicate important state agent choice action really matters relevance tuning produces feature detectors relevant predicting agent future success may relevant choosing next action agent detects feature actions produce outcomes equally good feature doesn make difference determining strategy even feature relevant predicting future success relevance tuning cannot tell features unimportant rarely developments neural networks unanticipated field statistics although researchers may recognize common threads first glance aware concept like importance based feature extraction statistics principal component analysis efficiently give structure feature space blind toward reinforcement seen agent therefore like approaches cannot guide feature extraction according reinforcements agent receives various state action combinations current performance task return top document djf reinforcement learning page finton cs wisc edu november