date tue nov gmt server ncsa content type text html last modified thu oct gmt content length cs memory management cs lecture notesmemory management contents allocating main memory algorithms memory management compaction garbage collection swapping allocating main memory first consider manage main core memory also called random access memory ram general memory manager provides two operations address allocate int size void deallocate address block procedure allocate receives request contiguous block size bytes memory returns pointer block procedure deallocate releases indicated block returning free pool reuse sometimes third procedure also provided address reallocate address block int new size takes allocated block changes size either returning part free pool extending larger block may always possible grow block without copying new location reallocate returns new address block memory allocators used variety situations unix process data segment system call make data segment bigger system call make smaller also system call quite expensive therefore library procedures called malloc free realloc manage space malloc realloc runs space necessary make system call c operators new delete dressed versions malloc free java operator new also uses malloc java runtime sustem calls free object found inaccessible garbage collection described operating system also uses memory allocator manage space used os data structures given user processes use saw several reasons might want multiple processes serving multiple interactive users controlling multiple devices also selfish reason os wants multiple processes memory time keep cpu busy suppose n processes memory called level multiprogramming process blocked waiting o fraction p time best case take turns blocked cpu busy provided n p example process ready time p cpu could kept completely busy five processes course real processes aren cooperative worst case could decide block time case cpu utilization fraction time cpu busy would p example processes decides randomly independently block chance n processes blocked time pn cpu utilization pn continuing example n p expected utilization would words cpu would busy time average see figure page text algorithms memory management clients memory mangager keep track allocated blocks worry happens client forgets block memory manager needs keep track holes common data structure doubly linked list holes sorted address data structure called free list free list doesn actually consume space head tail pointers since links holes stored holes provided hole least large two pointers satisfy allocate n request memory manager finds hole size least n removes list hole bigger n bytes split tail hole making smaller hole returns list satisfy deallocate request memory manager turns returned block hole data structure inserts appropriate place free list new hole immediately preceded followed hole holes coalesced bigger hole memory manager know big returned block usual trick put small header allocated block containing size block perhaps information allocate routine returns pointer body block header client doesn need know deallocate routine subtracts header size argument get address header client thinks block little smaller really long client colors inside lines problem client bugs scribbles header memory manager get completely confused frequent problem malloc unix programs written c c java system uses variety runtime checks prevent kind bug memory manager choose hole respond allocate request first might seem choose smallest hole big enough satisfy request strategy called best fit two problems first requires expensive search entire free list find best hole although fancier data structures used speed search importantly leads creation lots little holes big enough satisfy requests situation called fragmentation problem memory management strategies although particularly bad best fit one way aviod making little holes give client bigger block asked example might round requests next larger multiple bytes doesn make fragmentation go away hides unusable space form holes called external fragmentation unused space inside allocated blocks called internal fragmentation another strategy first fit simply scans free list large enough hole found despite name first fit generally better best fit leads less fragmentation still one problem small holes tend accumulate near beginning free list making memory allocator search farther farther time problem solved next fit starts search last one left wrapping around beginng end list reached yet another strategy maintain separate lists containing holes different size tanenbaum multiprogramming fixed partitions section page viewed extreme case approach number holes small approach works well application level different types objects created although might lots instances type also used general setting rounding requests one pre determined choices example memory mangager may round requests next power two bytes minimum say keep lists holes size etc assuming largest request possible megabyte requires lists approach taken implementations malloc approach eliminates external fragmentation entirely internal fragmenation may bad worst case occurs requests one byte power two another problem approach coalesce neighboring holes one possibility try system initialized splitting memory fixed set holes either size variety sizes request matched appropriate hole request smaller hole size entire hole allocated anyhow allocate block released simply returned appropriate free list implementations malloc use variant approach implementations split holes never coalesce interesting trick coalescing holes multiple free lists buddy system assume blocks holes sizes powers two requests always rounded next power two block hole starts address exact multiple size block buddy size adjacent combining block size n buddy creates properly aligned block size n example blocks size could start addresses etc blocks buddies combining gives block length similarly buddies buddies etc blocks buddies even though neighbors combining would give block size starting address multiple address block buddy easily calculated flipping nth bit right binary representation block address example pairs buddies binary case two addresses pair differ third bit right short find address buddy block taking exclusive address block size allocate block given size first round size next power two look list blocks size list empty split block next higher list list empty first add two blocks splitting block next higher list deallocating block first check see whether block buddy free combine block buddy add resulting block next higher free list allocations deallocations cascade higher higher lists compaction garbage collection run memory methods fail memory allocated much fragmentation malloc used allocate data segment unix process gives calls expensive os call expand data segment memory manager allocating real physical memory doesn luxury allocation attempt simply fails two ways delaying catastrophe compaction garbage collection compaction attacks problem fragmentation moving allocated blocks one end memory thus combining holes aside obvious cost copying important limitation compaction pointers block need updated block moved unless possible find pointers compaction possible pointers stored allocated blocks well places client memory manager situations pointers point start blocks also bodies example block contains executable code branch instruction might pointer another location block compaction performed three phases first new location block calculated determine distance block moved pointer updated adding amount block pointing moved finally data actually moved various clever tricks possible combine operations garbage collection finds blocks memory inaccessible returns free list compaction garbage collection normally assumes find pointers blocks within blocks outside possible still conservative garbage collection every word memory contains value appears pointer treated pointer conservative approach may fail collect blocks garbage never mistakenly collect accessible blocks three main approaches garbage collection reference counting mark sweep generational algorithms reference counting keeps block count number pointers block count drops zero block may freed approach practical situations higher level software keep track counts much hard hand even detect cyclic structures garbage consider cycle blocks pointed predecessor cycle block reference count entire cycle garbage mark sweep works two passes first mark non garbage blocks depth first search starting pointer outside void mark address b mark block b pointer p block b block pointed p marked mark p second pass sweeps blocks returns unmarked ones free list sweep pass usually also compaction decribed two problems mark sweep first amount work mark pass proportional amount non garbage thus memory nearly full lot work little payoff second mark phase lot jumping around memory bad virtual memory systems soon see third approach garbage collection called generational collection memory divided spaces space chosen garbage collection subsequent references objects space cause object copied new space old space either becomes empty returned free list least becomes sparse mark sweep garbage collection cheap empirical fact objects tend either short lived long lived words object survived likely live lot longer carefully choosing move objects referenced arrange spaces filled long lived objects unlikely become garbage garbage collect spaces seldom ever swapping else fails allocate simply fails case application program may adequate simply print error message exit os must able recover gracefully motivated memory management desire many processes memory batch system os cannot allocate memory start new job recover simply delaying starting job queue jobs waiting created os might want go list looking smaller job created right away approach maximizes utilization memory starve large jobs situation analogous short term cpu scheduling sjf gives optimal cpu utilization starve long bursts trick works aging job waits longer longer increase priority priority high os refuses skip looking recently arrived smaller job alterantive way avoiding starvation use memory allocation scheme fixed partitions holes split combined assuming job bigger biggest partion starvation provided time partition freed start first job line smaller partition however another choice analogous difference first fit best fit course want use best hole job smallest free partition least big job suppose next job line small small partitions currently use might want delay starting job look arrival queue job better uses partitions currently available policy re introduces possibility starvation combat aging disk available also swap blocked jobs disk job finishes first swap back jobs form disk allowing new jobs start job blocked either wants o short term scheduling algorithm says switch another job choice leaving memory swapping one way looking scheme increases multiprogramming level number jobs memory cost making much expensive switch jobs variant mlfq multi level feedback queues cpu scheduling algorithm particularly attractive situation queues numbered maximum job becomes ready enters queue zero cpu scheduler always runs job lowest numbered non empty queue e priority negative queue number runs job queue maximum quanta job block complete within time limit added next higher queue algorithm behaves like rr short quata short bursts get high priority incur overhead frequent swaps jobs long bursts number swaps limited logarithm burst size solomon cs wisc edu thu oct cst copyright marvin solomon rights reserved