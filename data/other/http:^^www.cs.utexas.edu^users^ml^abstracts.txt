mime version server cern date tuesday jan gmt content type text html content length last modified wednesday oct gmt machine learning papers abstracts machine learning papers abstracts view paper click open book image inductive logic programming natural language processing raymond j mooney proceedings th international inductive logic programming workshop pp stockholm sweden august paper reviews recent work applying inductive logic programming construction natural language processing systems developed system chill learns parser training corpus parsed sentences inducing heuristics control initial overly general shift reduce parser chill learns syntactic parsers well ones translate english database queries directly executable logical form atis corpus airline information queries used test acquisition syntactic parsers chill performed competitively recent statistical methods english queries small database u geography used test acquisition complete natural language interface parser chill acquired accurate existing hand coded system paper also includes discussion several issues work raised regarding capabilities testing ilp systems well summary current research directions combining symbolic connectionist learning methods refine certainty factor rule bases j jeffrey mahoney ph d thesis department computer sciences university texas austin may research describes system rapture designed revise rule bases expressed certainty factor format recent studies shown learning facilitated biased domain specific expertise also shown many real world domains require form probabilistic uncertain reasoning order successfully represent target concepts rapture designed take advantage results beginning set certainty factor rules along accurately labelled training examples rapture makes use symbolic connectionist learning techniques revising rules order correctly classify training examples modified version backpropagation used adjust certainty factors rules id information gain heuristic used add new rules upstart algorithm used create new hidden terms rule base results refining four real world rule bases presented demonstrate effectiveness combined approach two rule bases designed identify particular areas strands dna one identifying infectious diseases fourth attempts diagnose soybean diseases results rapture compared backpropagation c kbann learning systems rapture generally produces sets rules accurate systems often creating smaller sets rules using less training time integrating ebl ilp acquire control rules planning tara estlin raymond j mooney proceedings third international workshop multi strategy learning pp harpers ferry wv may msl approaches learning control information planning systems use explanation based learning generate control rules unfortunately ebl alone often produces overly complex rules actually decrease planning efficiency paper presents novel learning approach control knowledge acquisition integrates explanation based learning techniques inductive logic programming ebl used constrain inductive search selection heuristics help planner choose competing plan refinements scope one systems address learning control information newer partial order planners specifically scope learns domain specific control rules version ucpop planning algorithm resulting system shown produce significant speedup two different planning domains comparative experiments disambiguating word senses illustration role bias machine learning raymond j mooney proceedings conference empirical methods natural language processing pp philadelphia pa may paper describes experimental comparison seven different learning algorithms problem learning disambiguate meaning word context algorithms tested include statistical neural network decision tree rule based case based classification techniques specific problem tested involves disambiguating six senses word line using words current proceeding sentence context statistical neural network methods perform best particular problem discuss potential reason observed difference also discuss role bias machine learning importance explaining performance differences observed specific problems learning parse database queries using inductive logic programming john m zelle raymond j mooney proceedings thirteenth national conference aritificial intelligence pp portland august aaai paper presents recent work using chill parser acquisition system automate construction natural language interface database queries chill treats parser acquisition learning search control rules within logic program representing shift reduce parser uses techniques inductive logic programming learn relational control knowledge starting general framework constructing suitable logical form chill able train corpus comprising sentences paired database queries induce parsers map subsequent sentences directly executable queries experimental results complete database query application u geography show chill able learn parsers outperform pre existing hand crafted counterpart results demonstrate ability corpus based system produce purely syntactic representations also provide direct evidence utility empirical approach level complete natural language application novel application theory refinement student modeling paul baffes raymond j mooney proceedings thirteenth national conference aritificial intelligence pp portland august aaai theory refinement systems developed machine learning automatically modify knowledge base render consistent set classified training examples illustrate novel application techniques problem constructing student model intelligent tutoring system approach implemented authoring system called assert uses theory refinement introduce errors initially correct knowledge base models incorrect student behavior efficacy approach demonstrated evaluating tutor developed assert students tested classification task covering concepts introductory course c programming language system produced reasonably accurate models students received feedback based models performed significantly better post test students received simple reteaching qualitative multiple fault diagnosis continuous dynamic systems using behavioral modes siddarth subramanian raymond j mooney proceedings thirteenth national conference aritificial intelligence pp portland august aaai model based diagnosis systems gde sherlock concerned discrete static systems logic circuits use simple constraint propagation detect inconsistencies however sophisticated systems qsim qpe developed qualitative modeling simulation continuous dynamic systems present integration two lines research implemented system called qdocs multiple fault diagnosis continuous dynamic systems using qsim models main contributions algorithm include method propagating dependencies solving general constraint satisfaction problem method verifying consistency behavior model across time systematic experiments two realistic engineering systems demonstrate qdocs demonstrates best balance generality accuracy efficiency among competing methods multi strategy learning search control partial order planning tara estlin raymond j mooney proceedings thirteenth national conference aritificial intelligence pp portland august aaai research planning learning involved linear state based planners paper presents scope system learning search control rules improve performance partial order planner scope integrates explanation based inductive learning techniques acquire control rules partial order planner learned rules form selection heuristics help planner choose competing plan refinements specifically scope learns domain specific control rules version ucpop planning algorithm resulting system shown produce significant speedup two different planning domains integrating explanation based inductive learning techniques acquire search control planning tara estlin ph d proposal department computer sciences university texas austin planning systems become important tool automating wide variety tasks control knowledge guides planner find solutions quickly crucial efficient planning domains machine learning techniques enable planning system automatically acquire domain specific search control knowledge different applications past approaches learning control information usually employed explanation based learning ebl generate control rules unfortunately ebl alone often produces overly complex rules actually decrease rather improve overall planning efficiency paper presents novel learning approach control knowledge acquisition integrates explanation based learning techniques inductive logic programming learning system scope ebl used constrain inductive search control heuristics help planner choose competing plan refinements scope one systems address learning control information newer partial order planners specifically proposal describes scope learns domain specific control rules ucpop planning algorithm resulting system shown produce significant speedup two different planning domains effective pure ebl approach future research performed three main areas first scope learning algorithm extended include additional techniques constructive induction rule utility analysis second scope thoroughly tested several real world planning domains identified possible testbeds depth comparisons drawn scope competing approaches third scope implemented different planning system order test portability planning algorithms work demonstrate machine learning techniques powerful tool quest tractable real world planning lexical acquisition novel machine learning problem cynthia thompson raymond j mooney technical report artificial intelligence lab university texas austin paper defines new machine learning problem standard machine learning algorithms cannot easily applied problem occurs domain lexical acquisition ambiguous synonymous nature words causes difficulty using standard induction techniques learn lexicon additionally negative examples typically unavailable difficult construct domain one approach solve lexical acquisition problem presented along preliminary experimental results artificial corpus future work includes extending algorithm performing tests realistic corpus advantages decision lists implicit negative inductive logic programming mary elaine califf raymond j mooney technical report artificial intelligence lab university texas austin paper demonstrates capabilities foidl inductive logic programming ilp system whose distinguishing characteristics ability produce first order decision lists use output completeness assumption provide implicit negative examples use intensional background knowledge development foidl originally motivated problem learning generate past tense english verbs however paper demonstrates superior performance two different sets benchmark ilp problems tests finite element mesh design problem show foidl decision lists enable produce better results ilp systems whose results problem reported tests selection list processing problems bratko introductory prolog text demonstrate combination implicit negatives intensionality allow foidl learn correct programs far fewer examples foil learning parse decisions examples rich context ulf hermjakob raymond j mooney submitted th annual meeting association computational linguistics acl present knowledge context based system parsing natural language evaluate sentences wall street journal applying machine learning techniques system uses parse action examples acquired supervision generate deterministic shift reduce parser form decision structure relies heavily context encoded features describe morpholgical syntactical semantical aspects given parse state corpus based lexical acquisition semantic parsing cynthia thompson ph d proposal department computer sciences university texas austin building accurate efficient natural language processing nlp systems important difficult problem increasing interest automating process lexicon mapping words meanings one component typically difficult update changes one domain next therefore automating acquisition lexicon important task automating acquisition nlp systems proposal describes system wolfie word learning interpreted examples learns lexicon input consisting sentences paired representations meanings preliminary experimental results show system learn correct useful mappings correctness evaluated comparing known lexicon one learned training input usefulness evaluated examining effect using lexicon learned wolfie assist parser acquisition system previously lexicon hand built future work form extensions algorithm evaluation possible applications discussed refinement bayesian networks combining connectionist symbolic techniques sowmya ramanchandran ph d proposal department computer sciences university texas austin bayesian networks provide mathematically sound formalism representing reasoning uncertain knowledge widely used however acquiring capturing knowledge framework difficult growing interest formulating techniques learning bayesian networks inductively problem learning bayesian network given complete data explored depth problem learning networks unobserved causes still open proposal view problem perspective theory revision present novel approach adapts techniques developed revising theories symbolic connectionist representations thus assume learner given initial approximate network usually obtained expert technique inductively revises network fit data better proposed system two components one component revises parameters bayesian network known structure component revises structure network component parameter revision maps given bayesian network multi layer feedforward neural network parameters mapped weights neural network uses standard backpropagation techniques learn weights structure revision component uses qualitative analysis suggest revisions network fails predict data accurately first component implemented present results experiments real world classification problems show technique effective also discuss proposed structure revision algorithm plans experiments evaluate system well extensions system refinement based student modeling automated bug library construction paul baffes raymond mooney journal artificial intelligence education pp critical component model based intelligent tutoring sytems mechanism capturing conceptual state student enables system tailor feedback suit individual strengths weaknesses useful modeling technique must practical sense models easy construct effective sense using model actually impacts student learning research presents new student modeling technique automatically capture novel student errors using correct domain knowledge automatically compile trends across multiple student models approach implemented computer program assert using machine learning technique called theory refinement method automatically revising knowledge base consistent set examples using knowledge base correctly defines domain examples student behavior domain assert models student errors collecting refinements correct knowledege base necessary account student behavior efficacy approach demonstrated evaluating assert using students tested classification task covering concepts introductory course c programming language students received feedback based models automatically generated assert performed significantly better post test students received simple teaching comparative results using inductive logic programming corpus based parser construction john m zelle raymond j mooney symbolic connectionist statistical approaches learning natural language processing wermter e riloff g scheler eds spring verlag paper presents results recent experiments chill corpus based parser acquisition system chill treats language acquisition learning search control rules within logic program unlike many current corpus based approaches use statistical learning algorithms chill uses techniques inductive logic programming ilp learn relational representations chill flexible system used learn parsers produce syntactic parse trees case role analyses executable database queries reported experiments compare chill performance naive application ilp parser acquisition results show ilp techniques employed chill viable alternative statistical methods control rule framework fundamental chill success learning past tense english verbs using inductive logic programming raymond j mooney mary elaine califf symbolic connectionist statistical approaches learning natural language processing wermter e riloff g scheler eds spring verlag paper presents results using new inductive logic programming method called foidl learn past tense english verbs past tense task widely studied context symbolic connectionist debate previous papers presented results using various neural network decision tree learning methods developed technique learning special type prolog program called first order decision list defined ordered list clauses ending cut foidl based foil quinlan employs intensional background knowledge avoids need explicit negative examples particularly useful problems involve rules specific exceptions past tense task present results showing foidl learns accurate past tense generator significantly fewer examples previous methods hybrid learning search control partial order planning tara estlin raymond j mooney new directions ai planning m ghallab milani eds ios press pp paper presents results applying version dolphin search control learning system speed partial order planner dolphin integrates explanation based inductive learning techniques acquire effective clause selection rules prolog programs version ucpop partial order planning algorithm implemented prolog program dolphin used automatically learn domain specific search control rules help eliminate backtracking resulting system shown produce significant speedup several planning domains revising bayesian network parameters using connectionist methods sowmya ramachandran raymond j mooney proceedings international conference neural networks icnn special session knowledge based artificial neural networks washington dc june problem learning bayesian networks hidden variables known hard problem even simpler task learning conditional probabilities bayesian network hidden variables hard paper present approach learns conditional probabilities bayesian network hidden variables transforming multi layer feedforward neural network ann conditional probabilities mapped onto weights ann learned using standard backpropagation techniques avoid problem exponentially large anns focus bayesian networks noisy noisy nodes experiments real world classification problems demonstrate effectiveness technique qualitative multiple fault diagnosis continuous dynamic systems using behavioral modes siddarth subramanian ph d thesis department computer sciences university texas austin august systems like chemical plants power plants automobiles get complex online diagnostic systems becomingly increasingly important one ways rein complexity describing reasoning large systems describe using qualitative rather quantitative models model based diagnosis class diagnostic techniques use direct knowledge system functions instead expert rules detailing causes every possible set symptons broken system research builds standard methods model based diagnosis extends domain complex dynamic systems described using qualitative models motivate describe algorithm diagnosing faults dynamic system given qualitative model sequence qualitative states main contributions algorithm include method propagating dependencies solving general constraint satisfaction problem method verfying compatibility behavior model across time algorithm diagnose multiple faults uses models faulty behavior behavioral modes demonstrate techniques using implemented program called qdocs test realistic problems experiments model reaction control system rcs space shuttle level controller reaction tank show qdocs demonstrates best balance generality accuracy efficiency among known systems using inductive logic programming automate construction natural language parsers john m zelle ph d thesis department computer sciences university texas austin august designing computer systems understand natural language input difficult task recent years considerable interest corpus based methods constructing natural language parsers empirical approaches replace hand crafted grammars linguistic models acquired automated training language corpora common thread among methods date use propositional probablistic representations learned knowledge dissertation presents alternative approach based techniques subfield machine learning known inductive logic programming ilp ilp investigates learning relational first order rules provides empirical method acquiring knowledge within traditional symbolic parsing frameworks dissertation details architecture implementation evaluation chill computer system acquiring natural language parsers training corpora parsed text chill treats language acquisition learning search control rules within logic program implements shift reduce parser control rules induced using novel ilp algorithm handles difficult issues arising induction search control heuristics control rule framework induction algorithm crucial chill success main advantage chill propositional counterparts flexibility handling varied representations chill produced parsers various analyses including case role mapping detailed syntactic parse trees logical form suitable expressing first order database queries tasks accomplished within framework using single general learning method acquire new syntactic semantic categories resolving ambiguities experimental evidence aritificial real world corpora demonstrate chill learns parsers well better previous artificial neural network probablistic approaches comparable tasks database query domain goes beyond scope previous empirical approaches learned parser outperforms existing hand crafted system results support claim ilp techniques implemented chill represent viable alternative significant potential advantages neural network propositional probablistic approaches empirical parser construction inductive logic programming method corpus based parser construction john m zelle raymond j mooney submitted computational linguistics recent years considerable research corpus based methods parser construction common thread research use propositional representations learned knowledge paper presents alternative approach based techniques subfield machine learning known inductive logic programming ilp ilp investigates learning relational first order rules provides way using empricial methods acquire knowledge within traditional symbolic parsing frameworks describe novel method constructing deterministic prolog parsers corpora parsed sentences also discuss several advantages approach compared propositional alternatives present experimental results learning complete parsers using several corpora including atis corpus penn treebank comparison two methods employing inductive logic programming corpus based parser constuction john m zelle raymond j mooney working notes ijcai workshop new approaches learning natural language processing pp montreal quebec august paper presents results recent experiments chill corpus based parser acquisition system chill treats grammar acquisition learning search control rules within logic program unlike many current corpus based approaches use propositional probabilistic learning algorithms chill uses techniques inductive logic programming ilp learn relational representations reported experiments compare chill performance naive application ilp parser acquisition results show ilp techniques employed chill viable alternative propositional methods control rule framework fundamental chill success inducing logic programs without explicit negative examples john m zelle cynthia thompson mary elaine califf raymond j mooney proceedings fifth international workshop inductive logic programming leuven belguim sepetember paper presents method learning logic programs without explicit negative examples exploiting assumption output completeness mode declaration supplied target predicate training input assumed accompanied legal outputs outputs generated incomplete program implicitly represent negative examples however large numbers ground negative examples never need generated method incorporated two ilp systems chillin ifoil use intensional background knowledge tests two natural language acquisition tasks case role mapping past tense learning illustrate advantages approach acquisition lexicon semantic representations sentences cynthia thompson rd annual meeting association computational linguistics pp boston ma july acl system wolfie acquires mapping words semantic representation presented preliminary evaluation performed tree least general generalizations tlggs representations input sentences performed assist determining representations individual words sentences best guess meaning word tlgg overlaps highest percentage sentence representations word appears promising experimental results non artificial data set presented induction first order decision lists results learning past tense english verbs raymond j mooney mary elaine califf journal artificial intelligence research pp paper presents method inducing logic programs examples learns new class concepts called first order decision lists defined ordered lists clauses ending cut method called foidl based foil employs intensional background knowledge avoids need explicit negative examples particularly useful problems involve rules specific exceptions learning past tense english verbs task widely studied context symbolic connectionist debate foidl able learn concise accurate programs problem significantly fewer examples previous methods connectionist symbolic multiple fault diagnosis using general qualitative models fault modes siddarth subramanian raymond j mooney working notes ijcai workshop engneering problems qualitative reasoning monreal quebec august paper describes approach diagnosis systems described qualitative differential equations represented qsim models implemented system qdocs described performs multiple fault fault model based diagnosis using constraint satisfaction techniques qualitative behaviors systems described models demonstrate utility system accurately diagnosing randomly generated faults using simulated behaviors portion reaction control system space shuttle learning qualitative models systems multiple operating regions sowmya ramachandran raymond j mooney benjamin j kuipers proceedings eight international workshop qualitative reasoning physical systems pp nara japan june qr problem learning qualitative models physical systems observations behaviour addressed several researchers recent years current techniques limit learning single qualitative differential equation model entire system however many systems several qualitative differential equations underlying paper present approach learning models systems technique divides behaviours segments explained single qualitative differential equation qualitative model segment generated using existing techniques learning single model show results applying technique several examples demonstrate effective multiple fault diagnosis using general qualitative models fault modes siddarth subramanian raymond j mooney working papers fifth international workshop principles diagnosis pp new paltz ny paper describes approach diagnosis systems described qualitative differential equations represented qsim models implemented system qdocs described performs multiple fault fault model based diagnosis using constraint satisfaction techniques qualitative behaviors systems described models demonstrate utility system accurately diagnosing randomly generated faults using simulated behaviors portion reaction control system space shuttle automatic student modeling bug library construction using theory refinement paul baffes ph d thesis department computer sciences university texas austin december history computers education characterized continuing effort construct intelligent tutorial programs adapt individual needs student one one setting critical component intelligent tutorials mechanism modeling conceptual state student system able tailor feedback suit individual strengths weaknesses primary contribution research new student modeling technique automatically capture novel student errors using correct domain knowledge automatically compile trends across multiple student models bug libraries approach implemented computer program assert using machine learning technique called theory refinement method automatically revising knowledge base consistent set examples using knowledge base correctly defines domain examples student behavior domain assert models student errors collecting refinements correct knowledge base necessary account student behavior efficacy approach demonstrated evaluating assert using students tested classification task using concepts introductory course c programming language students received feedback based models automatically generated assert performed significantly better post test students received simple reteaching inductive learning abductive diagnosis cynthia thompson raymond j mooney proceedings twelfth national conference ai pp seattle wa july aaai new inductive learning system lab learning abduction presented acquires abductive rules set training examples goal find small knowledge base used abductively diagnoses training examples correctly generalizes well unseen examples contrasts past systems inductively learn rules used deductively training example associated potentially multiple categories disorders instead one typical learning systems lab uses simple hill climbing algorithm efficiently build rule base set covering abductive system lab experimentally evaluated compared learning systems expert knowledge base domain diagnosing brain damage due stroke comparing methods refining certainty factor rule bases j jeffrey mahoney raymond j mooney proceedings eleventh international workshop machine learning pp rutgers nj july ml paper compares two methods refining uncertain knowledge bases using propositional certainty factor rules first method implemented rapture system employs neural network training refine certainties existing rules uses symbolic technique add new rules second method based one used kbann system initially adds complete set potential new rules low certainty allows neural network training filter adjust rules experimental results indicate former method results significantly faster training produces much simpler refined rule bases slightly greater accuracy modifying network architectures certainty factor rule base revision j jeffrey mahoney raymond j mooney proceedings international symposium integrating knowledge neural heuristics pp pensacola fl may isiknh paper describes rapture system revising probabilistic rule bases converts symbolic rules connectionist network trained via connectionist techniques uses modified version backpropagation refine certainty factors rule base uses id information gain heuristic quinlan add new rules work currently way finding improved techniques modifying network architectures include adding hidden units using upstart algorithm frean case made via comparison fully connected connectionist techniques keeping rule base close original possible adding new input units needed combining top bottom techniques inductive logic programming john m zelle raymond j mooney joshua b konvisser proceedings eleventh international workshop machine learning pp rutgers nj july ml paper describes new method inducing logic programs examples attempts integrate best aspects existing ilp methods single coherent framework particular combines bottom method similar golem top method similar foil also includes method predicate invention similar champ elegant solution noisy oracle problem allows system learn recursive programs without requiring complete set positive examples systematic experimental comparisons golem foil range problems used clearly demonstrate advantages approach inducing deterministic prolog parsers treebanks machine learning approach john m zelle raymond j mooney proceedings twelfth national conference ai pp seattle wa july aaai paper presents method constructing deterministic context sensitive prolog parsers corpora parsed sentences approach uses recent machine learning methods inducing prolog rules examples inductive logic programming discuss several advantages method compared recent statistical methods present results learning complete parsers portions atis corpus integrating ilp ebl raymond j mooney john m zelle sigart bulletin volume number jan pp paper presents review recent work integrates methods inductive logic programming ilp explanation based learning ebl ilp ebl methods complementary strengths weaknesses number recent projects effectively combined systems better performance either individual approaches particular integrated systems developed guiding induction prior knowledge ml smart focl grendel refining imperfect domain theories forte audrey rx learning effective search control knowledge axa ebl dolphin extending theory refinement m n rules paul baffes raymond j mooney informatica pp recent years machine learning research started addressing problem known theory refinement goal theory refinement learner modify incomplete incorrect rule base representing domain theory make consistent set input training examples paper presents major revision either propositional theory refinement system two issues discussed first show run time efficiency greatly improved changing exhaustive scheme computing repairs iterative greedy method second show extend either refine mofn rules resulting algorithm neither new either order magnitude faster produces significantly accurate results theories fit mofn format demonstrate advantages neither present experimental results two real world domains inductive learning abductive diagnosis cynthia thompson m thesis department computer sciences university texas austin new system learning induction called lab presented lab learning abduction learns abductive rules based set training examples goal find small knowledge base used abductively diagnoses training examples correctly addition generalizing well unseen examples contrast past systems inductively learn rules used deductively abduction particularly well suited diagnosis given set symptoms manifestations want output set disorders explain manifestations present training example associated potentially multiple categories instead one case typical learning systems building knowledge base requires choice multiple possibilities number possibilities grows exponentially number training examples one method choosing best knowledge base described implemented final system experimentally evaluated using data domain diagnosing brain damage due stroke compared learning systems knowledge base produced expert results promising rule base learned simpler expert knowledge base rules learned one systems accuracy learned rule base predicting areas damaged better systems well expert knowledge base learning model students using theory refinement detect misconceptions paul baffes ph d proposal department computer sciences university texas austin new student modeling system called assert described uses domain independent learning algorithms model unique student errors automatically construct bug libraries assert consists two learning phases first application theory refinement techniques constructing student models correct theory domain tutored second learning cycle automatically constructs bug library extracting common refinements multiple student models used bias future modeling efforts initial experimental data presented suggests assert effective modeling system induction techniques previously explored student modeling automatic bug library construction significantly enhances subsequent modeling efforts learning search control heuristics logic programs applications speedup learning language acquisition john m zelle ph d proposal department computer sciences university texas austin paper presents general framework learning search control heuristics logic programs used improve efficiency accuracy knowledge based systems expressed definite clause logic programs approach combines techniques explanation based learning recent advances inductive logic programming learn clause selection heuristics guide program execution two specific applications framework detailed dynamic optimization prolog programs improving efficiency natural language acquisition improving accuracy area program optimization prototype system dolphin able transform intractable specifications polynomial time algorithms outperforms competing approaches several benchmark speedup domains prototype language acquisition system chill also described capable automatically acquiring semantic grammars uniformly incorprate syntactic semantic constraints parse sentences case role representations initial experiments show approach able construct accurate parsers generalize well novel sentences significantly outperform previous approaches learning case role mapping based connectionist techniques planned extensions general framework specific applications well plans evaluation also discussed combining foil ebg speed logic programs john m zelle raymond j mooney proceedings thirteenth international joint conference artificial intelligence pp chambery france ijcai paper presents algorithm combines traditional ebl techniques recent developments inductive logic programming learn effective clause selection rules prolog programs control rules incorporated original program significant speed may achieved algorithm shown improvement competing ebl approaches several domains additionally algorithm capable automatically transforming intractable algorithms ones run polynomial time symbolic revision theories m n rules paul baffes raymond j mooney proceedings thirteenth international joint conference artificial intelligence pp chambery france ijcai paper presents major revision either propositional theory refinement system two issues discussed first show run time efficiency greatly improved changing exhaustive scheme computing repairs iterative greedy method second show extend either refine m n rules resulting algorithm neither new either order magnitude faster produces significantly accurate results theories fit m n format demonstrate advantages neither present preliminary experimental results comparing either various systems refining dna promoter domain theory learning semantic grammars constructive inductive logic programming john m zelle raymond j mooney proceedings eleventh national conference american association artificial intelligence pp washington d c july aaai automating construction semantic grammars difficult interesting problem machine learning paper shows semantic grammar acquisition problem viewed learning search control heuristics logic program appropriate control rules learned using new first order induction algorithm automatically invents useful syntactic semantic categories empirical results show learned parsers generalize well novel sentences perform previous approaches based connectionist techniques combining connectionist symbolic learning refine certainty factor rule bases j jeffrey mahoney raymond j mooney connection science pp special issue architectures integrating neural symbolic processing paper describes rapture system revising probabilistic knowledge bases combines connectionist symbolic learning methods rapture uses modified version backpropagation refine certainty factors mycin style rule base uses id information gain heuristic add new rules results refining three actual expert knowledge bases demonstrate combined approach generally performs better previous methods refinement first order horn clause domain theories bradley l richards raymond j mooney machine learning pp knowledge acquisition difficult time consuming task error prone human activity task automatically improving existing knowledge base using learning methods addressed new class systems performing theory refinement recently systems limited propositional theories paper presents system forte first order revision theories examples refining first order horn clause theories moving first order representation opens many new problem areas logic program debugging qualitative modelling beyond reach propositional systems forte uses hill climbing approach revise theories identifies possible errors theory calls library operators develop possible revisions best revision implemented process repeats revisions possible operators drawn variety sources including propositional theory refinement first order induction inverse resolution forte tested several domains including logic programming qualitative modelling encouraging experimental results learning cnf raymond j mooney machine learning pp paper presents results comparing three inductive learning systems using different representations concepts namely cnf formulae dnf formulae decision trees cnf learner performs surprisingly well results five natural data sets show frequently trains faster produces accurate simpler concepts probable explanation superior performance systems susceptible replication problem belief revision context abductive explanation siddarth subramanian technical report ai artificial intelligence lab university texas austin march proposal presents approach explanation incorporates paradigms belief revision abduction present algorithm combines techniques system called brace preliminary implementation algorithm show applicability brace approach wide range domains including scientific discovery device diagnosis plan recognition finally describe proposals new implementation new application domains system extensions approach first order horn clause abductive system use plan recognition diagnosis hwee tou ng raymond j mooney submitted journal publication diverse set intelligent activities including natural language understanding diagnosis requires ability construct explanations observed phenomena paper view explanation abduction abductive explanation consistent set assumptions together background knowledge logically entails set observations successfully built domain independent system accel knowledge variety domains uniformly encoded first order horn clause axioms general purpose abduction algorithm aaa efficiently constructs explanations various domains caching partial explanations avoid redundant work empirical results show caching partial explanations achieve order magnitude speedup run time applied abductive system two general tasks plan recognition text understanding diagnosis medical diseases logic circuits dynamic systems results indicate accel general purpose system capable plan recognition diagnosis yet efficient enough practical utility abductive plan recognition diagnosis comprehensive empirical evaluation hwee tou ng raymond j mooney proceedings third international conference principles knowledge representation reasoning pp cambridge ma october realized quite time within ai abduction general model explanation variety tasks empirical investigations practical feasibility general logic based abductive approach explanation paper present extensive empirical results applying general abductive system accel moderately complex problems plan recognition diagnosis plan recognition accel tested short narrative texts inferring characters plans actions described text medical diagnosis accel diagnosed real world patient cases involving brain damage due stroke previously addressed set covering methods accel also uses abduction accomplish model based diagnosis logic circuits full adder continuous dynamic systems temperature controller water balance system human kidney results indicate general purpose abduction effective efficient mechanism solving problems plan recognition diagnosis automatic abduction qualitative models bradley l richards ina kraan benjamin j kuipers proceedings tenth national conference artificial intelligence pp san jose ca july describe method automatically abducing qualitative models descriptions behaviors generate either quantitative qualitative data models form qualitative differential equations suitable use qsim constraints generated filtered comparison input behaviors dimensional analysis user provides complete information input behaviors dimensions input variables resulting model unique maximally constrainted guaranteed reproduce input behaviors user provides incomplete information method still generate model reproduces input behaviors model may longer unique incompleteness take several forms missing dimensions values variables entire variables learning relations pathfinding bradley l richards raymond j mooney proceedings tenth national conference artificial intelligence pp san jose ca july first order learning systems e g foil focl forte generally rely hill climbing heuristics order avoid combinatorial explosion inherent learning first order concepts however hill climbing leaves systems vulnerable local maxima local plateaus present method called relational pathfinding proven highly effective escaping local maxima crossing local plateaus present algorithm provide learning results two domains family relationships qualitative model building speeding logic programs combining ebg foil john m zelle raymond j mooney proceedings machine learning workshop knowledge compilation speedup learning aberdeen scotland july paper presents algorithm combines traditional ebl techniques recent developments inductive logic programming learn effective clause selection rules prolog programs control rules incorporated original program significant speed may achieved algorithm produces ebl like speed problem solvers capable automatically transforming intractable algorithms ones run polynomial time combining symbolic neural learning revise probabilistic theories j jeffrey mahoney raymond j mooney proceedings machine learning workshop integrated learning real domains aberdeen scotland july paper describes rapture system revising probabilistic theories combines symbolic neural network learning methods rapture uses modified version backpropagation refine certainty factors mycin style rule base uses id information gain heuristic add new rules results two real world domains demonstrate combined approach performs well better previous methods growing layers perceptrons introducing extentron algorithm paul baffes john m zelle proceedings international joint conference neural networks pp baltimore maryland june ideas presented based two observations perceptrons perceptron learning algorithm cycles among hyperplanes hyperplanes may compared select one gives best split examples always possible perceptron build hyperplane separates least one example rest describe extentron grows multi layer networks capable distinguishing non linearly separable data using simple perceptron rule linear threshold units resulting algorithm simple fast scales well large problems retains convergence properties perceptron completely specified using two parameters results presented comparing extentron neural network paradigms symbolic learning systems using theory revision model students acquire stereotypical errors paul baffes raymond j mooney proceedings fourteenth annual conference cognitive science society pp bloomington july student modeling identified important component long term development intelligent computer aided instruction icai systems two basic approaches evolved model student misconceptions one uses static predefined library user bugs contains misconceptions modeled system uses induction learn student misconceptions scratch present third approach uses machine learning technique called theory revision using theory revision allows system automatically construct bug library use modeling retaining flexibility address novel errors preliminary pac analysis theory revision raymond j mooney computational learning theory natural learning systems vol petsche judd hanson eds mit press pp paper presents preliminary analysis sample complexity theory revision within framework pac probably approximately correct learnability theory formalizing notion initial theory close correct theory show sample complexity optimal propositional horn clause theory revision algorithm o ln delta d ln d n epsilon d em syntactic distance initial correct theories size initial theory n number observable features epsilon delta standard pac error probability bounds paper also discusses problems raised computational complexity theory revision automated debugging logic programs via theory revision raymond j mooney bradley l richards proceedings second international workshop inductive logic programming tokyo japan june paper presents results using theory revision system automatically debug logic programs forte recently developed system revising function free horn clause theories given theory set training examples performs hill climbing search attempt minimally modify theory correctly classify examples forte makes use methods propositional theory revision horn clause induction foil inverse resolution system successfully used debug logic programs written undergraduate students programming languages course batch versus incremental theory refinement raymond j mooney proceedings aaai spring symposium knowledge assimilation standford ca march existing theory refinement systems incremental however theory refinement system whose input output theories compatible used incrementally assimilate data evolving theory done continually feeding revised theory back input theory incremental batch approach system assimilates batch examples step seems appropriate existing theory revision systems experimental results either theory refinement system demonstrate approach frequently increases efficiency without significantly decreasing accuracy simplicity resulting theory however system produces bad initial changes theory based small amount data bad revisions snowball result overall decrease performance multistrategy approach theory refinement raymond j mooney dirk ourston machine learning multistrategy approach vol iv r michalski g teccuci eds pp morgan kaufman san mateo ca chapter describes multistrategy system employs independent modules deductive abductive inductive reasoning revise arbitrarily incorrect propositional horn clause domain theory fit set preclassified training instances combining diverse methods either able handle wider range imperfect theories theory revision systems guaranteeing revised theory consistent training data either successfully revised two actual expert theories one molecular biology one plant pathology results confirm hypothesis using multistrategy system learn theory data gives better results using either theory data alone integrating theory data category learning raymond j mooney categorization humans machines psychology learning motivation vol g nakamura r taraban d l medin eds pp academic press orlando fl recent results machine learning cognitive psychology demonstrate effective category learning involves integration theory data first theories bias induction affecting category definitions extracted set examples second conflicting data cause theories revised third theories alter representation data feature formation chapter reviews two machine learning systems attempt integrate theory data one ways iou uses domain theory acquire part concept definition focus induction unexplained aspects data either uses data revise imperfect theory uses theory add abstract features data recent psychological experiments reveal machine learning systems exhibit several important aspects human category learning specifically iou used successfully model recent experimental results effect functional knowledge category learning theory refinement combining analytical empirical methods dirk ourston raymond j mooney artificial intelligence pp article describes comprehensive approach automatic theory revision given imperfect theory approach combines explanation attempts incorrectly classified examples order identify failing portions theory theory fault correlated subsets examples used inductively generate correction corrections focused tend preserve structure original theory system starts approximate domain theory general fewer training examples required attain given level performance classification accuracy compared purely empirical system approach applies classification systems employing propositional horn clause theory system tested variety application domains results presented problems domains molecular biology plant disease diagnosis induction unexplained using overly general domain theories aid concept learning raymond j mooney machine learning pp paper describes evaluates approach combining empirical explanation based learning called induction unexplained iou iou intended learning concepts partially explained overly general domain theory eclectic evaluation method presented includes results three major approaches empirical theoretical psychological empirical results shows iou effective refining overly general domain theories learns accurate concepts fewer examples purely empirical approach application theoretical results pac learnability theory explains iou requires fewer examples iou also shown able model psychological data demonstrating effect background knowledge human learning efficient first order horn clause abduction system based atms hwee tou ng raymond j mooney proceedings ninth national conference artificial intelligence pages anaheim ca july paper presents algorithm first order horn clause abduction uses atms avoid redundant computation algorithm either efficient general previous abduction algorithm since computing minimal abductive explanations intractable also present heuristic version algorithm uses beam search compute subset simplest explanations present empirical results broad range abduction problems text understanding plan recognition device diagnosis demonstrate algorithm least order magnitude faster alternative abduction algorithm use atms improving shared rules multiple category domain theories dirk ourston raymond j mooney proceedings eighth international machine learning workshop pp evanston il june paper presents approach improving classification performance multiple category theory correcting intermediate rules shared among categories using technique performance theory one category improved training entirely different category examples technique presented experimental results given constructive induction theory refinement raymond j mooney dirk ourston proceedings eighth international machine learning workshop pp evanston il june paper presents constructive induction techniques recently added either theory refinement system additions allow either handle arbitrary gaps top middle bottom incomplete domain theory intermediate concept utilization employs existing rules theory derive higher level features use induction intermediate concept creation employs inverse resolution introduce new intermediate concepts order fill gaps theory span multiple levels revisions allow either make use imperfect domain theories ways typical previous work constructive induction theory refinement result either able handle wider range theory imperfections existing theory refinement system theory refinement noisy data raymond j mooney dirk ourston technical report ai artificial intelligence lab university texas austin march paper presents method revising approximate domain theory based noisy data basic idea avoid making changes theory account small amount data method implemented either propositional horn clause theory revision system paper presents empirical results artificially corrupted data show method successfully prevents fitting words data noisy performance novel test data considerably better revising theory completely fit data data noisy noise processing causes significant degradation performance finally noise processing increases efficiency decreases complexity resulting theory role coherence abductive explanation hwee tou ng raymond j mooney proceedings eighth national conference artificial intelligence pages boston ma abduction important inference process underlying much human intelligent activities including text understanding plan recognition disease diagnosis physical device diagnosis paper describe problems encountered using abduction understand text present solutions overcome problems solutions propose center around use different criterion called explanatory coherence primary measure evaluate quality explanation addition explanatory coherence plays important role construction explanations determining appropriate level specificity preferred explanation guiding heuristic search efficiently compute explanations sufficiently high quality estlin cs utexas edu