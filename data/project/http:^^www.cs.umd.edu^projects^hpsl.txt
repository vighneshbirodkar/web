date wed nov gmt server apache ssl b content type text html content length last modified thu oct gmt chaos project chaos research group university maryland college park developed methods making possible produce portable compilers runtime libraries map broad range challenging applications onto high performance computer architectures major focus work develop techniques irregular scientific problems e problems unstructured sparse adaptive block structured group works extensively applications developers many disciplines parallel compiler vendors many concepts first described prototyped project making way high performance fortran ongoing second round language definition work also leading development runtime support meta chaos couple runtime libraries used data task parallel compilers meta chaos central component common compiler runtime support developed parallel compiler runtime consortium currently developing techniques allow parallel compute data objects offer services remotely connected clients goal develop techniques make possible compose programs running combination distributed memory shared memory networked microcomputers workstations motivating research software interoperability scenarios associated two classes applications first class sensor data processing integration second complex physical simulations developed early prototypes data parallel program coupling software employed prototype demonstrate ability couple separately executing high performance fortran programs couple high performance fortran programs applications developed using maryland chaos multiblock parti libraries based upon experiences developing runtime libraries parallelizing applications developed several compilation techniques goal able automate hand parallelization optimization techniques use compilers employed fortran d compilation system developed primarily rice university infrastructure implementation techniques generating efficient code applications multiple levels indirection developed index flattening technique based upon notion program slicing technique transforms loop multiple levels indirection series loops single level indirection also observed aggressive interprocedural optimizations required deal large applications irregular accesses data large o requirements developed interprocedural partial redundancy elimination ipre technique performing interprocedural placement communication preprocessing collective communication statements currently working interprocedural balanced code placement ibcp allow us overlap computation communication across procedure boundaries also working generating distributed memory code fortran codes use pointers recursive data structures joel saltz chaos parti runtime support library current areas research applications high performance o compilers tools local resources publications funded projects code download presentations hpf benchmarks faculty dr joel saltz dr michael j franklin dr jeff hollingsworth dr pete keleher dr chau wen tseng research faculty dr anurag acharya dr guy edjlali dr alan sussman affiliated faculty dr gagan agrawal dr kelvin bryant dr raja das dr paul havlak faculty research assistant wes stevens visiting collaborators dr gopal patnaik naval research laboratory edward suh national institutes health graduate students robert e bennett michael beynon chialin chang yuan shin hwang bongki moon mudumbai ranganathan daniel savarese shamik sharma mustafa uysal research programmer jim humphries undergraduate students dan ridge greg seidman sites interest parallel tools consortium northeast parallel architectures center home page task parallelism fortran center research parallel computation crpc caltech concurrent supercomputing facilities ccsf argonne national laboratory high performance fortran forum hpff los alamos national laboratory university tennessee knoxville university illinois