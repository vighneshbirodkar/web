mime version server cern date sunday dec gmt content type text html content length last modified thursday jan gmt jpeg encoding using perceptual quality multimedia systemsjpeg encoding using perceptual quality nobuhiko mukai mukai cs cornell edu lucy y wu yuwu cs cornell edu mikio sakurai msakurai sunlab cit cornell edu abstract key point image compression achieve low bit rate digital representation input image video signal minimum perceived loss picture quality past several years many attempts incorporate perceptual masking models image compression system based pre quantization developed two new models compared jpeg default setting models significantly lower bit rate keep almost image quality introduction key point image compression achieve low bit rate digital representation input image video signal minimum perceived loss picture quality since ultimate criterion quality judged measured human receiver important compression coding algorithm minimizes perceptually meaningful measures signal distortion jpeg default quantization tables qt based psychovisual thresholding derived empirically one qt available every image default qt image independent used achieve optimized compression result specific image perceptual models developed calculate image dependent qt every block image contributes different properties total image one qt best whole image always best every block quantize every block using different qt specifically suitable block get optimized compression result every block jpeg allows one qt image pre quantization proposed johnston safranek j every block one specific masking threshold calculated used zero perceptual irrelevant coefficients coefficients passed unchanged one base qt finally used quantize remaining coefficients block despite benefits simple implementation j model disadvantage computing single masking elevation input block means information distribution energy within block problem overcome applying contrast masking model dct coefficient model computation model somewhat complex led us design second one model based luminance ratio block total image replace j model second model single masking elevation problem calculation simple test result shows compared jpeg default setting models reduced bit rate little perceived loss quality rest paper organized follows section describes algorithms prequantize jpeg image section describes two perceptual models designed us section describes detailed evaluation models section reviews related work future extensions prequantization quantization baseline jpeg encoder consists three major components forward dct quantization entropy coding step quantization take raw output dct quantize coefficients dividing coefficient coefficient qt rounding nearest integer purpose quantization achieve compression representing dct coefficients greater precision necessary achieve desired image quality words goal processing step discard information visually significant perceptual model many studies attempted derive computational model visual masking level block input image model attempts determine degree features present block inhibit visual system distortion introduced compression decompression process points possible determine masking threshold dct coefficient j model johnston safranek developed framework computing locally adaptive masking model based engineering framework assume total masking level block input represented base masking level multiplicative elevation factors represent contribution input dependent properties visual system total mask model may expressed m u v global u v x local u v m u v masking level frequency u v input block global u v base masking level depends global properties local u v handles image specific local variation masking threshold adaptation derived function block standard deviation using following formula figure j model applies ac coefficients masking elevation dc coefficient always set unity model advantage simple implementation works well practice disadvantage computing single masking elevation input block figure illustrates structure encoder forward transformation identical one baseline jpeg point dct coefficients input perceptual model generates data dependent quantization table block table raw dct coefficients input pre quantizer purpose module zero coefficients magnitude less corresponding entry quantization table block pass coefficients unchanged finally prequantized coefficients quantized entropy coded standard jpeg dequantization step base qt used figure structure encoder prequantization models models intends take advantage prequantization method model j model uses perceptual model consider distribution energy within block calculating block specific masking threshold overcome problem employ visual masking widely used vision models based work legge foley given dct coefficient c u v luminance threshold u v masked threshold m u v m u v max u v c u v w u v u v w u v w constant lies w masking occurs w weber law behavior experiment empirical value w used implementation calculate masking threshold calculate luminance threshold using peterson model suggested watson addition indicated jpeg standard jpeg default quantization tables based psychovisual thresholding derived empirically divided almost indistinguishable image reconstructed means default qt treated general luminance threshold replaced u v equation jpeg default qt value global masking level used default jpeg qt model masking threshold computation model rather complex led us design second model model based luminance ratio block total image model single masking elevation problem calculation simple basically model follows j masking model equation calculation multiplicative elevation factors local u v use luminance ratio block total image well known weber law expressed df f constant f luminance df noticeable difference equation means perception sensitive luminance contrast rather absolute luminance values given luminance f block luminance little bit differ luminance f block less visible drop lot perceptually unimportant information adaptation derived function ratio block average luminance luminance average total image using following formula figure model masking model based luminance ratio maximum threshold elevation max e minimum threshold minimum luminance ratio min parameters need experiment global masking level used default jpeg qt image quality bitrate compared bitrate bits pixel image quality model model baseline jpeg model first need optimize parameter worked several images found two parameters max e min strongly sensitive snr different value luminance ratio parameter min snr almost constant threshold elevation parameter max e weak relation snr gets bigger snr becomes worse feature common images table shows result got image lena table parameter max e min dependence snr following experiment choose preferable value max e min parameter model five images used experiment photo human face lena flower scene flowers photo animal face baboon two photo airplane f pitts bitrate calculated compressing image file using pack huffman coding program evaluation image quality used two evaluation method first snr signal noise ratio order provide insight subjective quality models used dcon metric algorithm takes input two images reference test compare difference luminance pixel pixel formula follows dcon n sum y y y y method simple competitive complicated human eye model metric table summarize results experiments table image quality snr dcon vs bitrate model model compress better baseline jpeg almost perceptual loss quality figure shows one example flowers output image models comparison original image baseline jpeg original image baseline jpeg model model figure sample image comparison related work conclusions many attempts incorporate perceptual masking model image compression systems johnston safranek model watson model perhaps well known perceptual model j model investigated locally optimized prequantization table watson model investigated image dependent masking model incorporates global conditions also accounts local contrast masking klein u c berkery optometry school reported techniques improving quality jpeg high compression rate viewpoint vision community suggests improved human vision models quantization step could made effective considering effects mean luminance color bandpass filters spatio temporal frequency orientation contrast masking human contrast sensitivity primary contribution work details encoding specific prequantization algorithms compress images high compression rate minimal artifact future work include extending work include human eye related factors spatio temporal frequency orientation references johnston j d safranek r j perceptually tuned sub band image coder image dependent quantization post quantization data compression proc icassp glasgow scotland vol ma may pp g e legge j m foley contrast masking human vision journal optical society america j ahumada h peterson luminance model based dct quantization color image compression spie human vision visual processing digital display iii vol pp watson b dct quantization matrices visually optimized individual images spie human vision visual processing digital display iv vol feb pp daniel r fuhrmann john baro jerome r cox experimental evaluation psychophysical distortion metrics jpeg encoded images spie human vision visual processing digital display vol pp j daly visible difference predictor algorithm assessment image fidelity spie human vision visual processing digital display iii vol pp j l mannos d j sakrison effects visual fidelity criterion encoding images ieee transaction information theory pp stanley klein amnon d silverstein thom carney relevance human vision jpeg dct compression spie human vision visual processing digital display iii vol pp postscript file file last modified december