mime version server cern date sunday nov gmt content type text html content length last modified wednesday sep gmt query humming musical information retrieval audio database acm multimedia electronic proceedings november san francisco california query humming musical information retrieval audio database asif ghias department computer science upson hall cornell university ithaca ny us ghias cs cornell edu jonathan logan department computer science upson hall cornell university ithaca ny us logan ghs com david chamberlin school electrical engineering phillips hall cornell university ithaca ny us chamberlin engr sgi com brian c smith department computer science upson hall cornell university ithaca ny us bsmith cs cornell edu acm copyright notice abstract emergence audio video data types databases require new information retrieval methods adapted specific characteristics needs data types effective natural way querying musical audio database humming tune song paper system querying audio database humming described along scheme representing melodic information song relative pitch changes relevant difficulties involved tracking pitch enumerated along approach followed performance results system indicating effectiveness presented table contents introduction system architecture tracking pitch hummed queries tracking pitch searching database evaluation robustness performance future directions related work references introduction next generation databases include image audio video data addition traditional text numerical data data types require query methods appropriate natural type respective data instance natural way query image database retrieve images based operations images sketches supplied input similarly natural way querying audio database songs hum tune song system would useful multimedia database containing musical data providing alternative natural way querying one also imagine widespread use system commercial music industry music radio tv stations music stores even one personal use paper address issue specify hummed query report efficient query execution implementation using approximate pattern matching approach hinges upon observation melodic contour defined sequence relative differences pitch successive notes used discriminate melodies handel indicates melodic contour one important methods listeners use determine similarities melodies currently use alphabet three possible relationships pitches u d representing situations note previous note pitch tracked quite robustly current implementation system successfully able retrieve songs within notes database currently comprises collection parts melody otherwise songs suggesting three way discrimination would useful finding particular song among private music collection higher resolutions probably necessary larger databases paper organized follows first section describes architecture current system second section describes pitch important representing melodic contents songs several techniques tracking pitch tried discarded method settled next discuss pattern matching used current implementation database last two sections describe evaluation current system specify future extensions considering incorporating existing system system architecture three main components system pitch tracking module melody database query engine architecture illustrated figure operation system straight forward queries hummed microphone digitized fed pitch tracking module result contour representation hummed melody fed query engine produces ranked list matching melodies figure system architecture database melodies acquired processing public domain midi songs stored flat file database pitch tracking performed matlab chosen built audio processing capabilities ease testing number algorithms within hummed queries may recorded variety formats depending upon platform specific audio input capabilities matlab experimented bit khz wav format pentium system bit khz au format sun sparcstation query engine uses approximate pattern matching algorithm described order tolerate humming errors tracking pitch hummed queries section describes user input system humming converted sequence relative pitch transitions note input classified one three ways note either previous note higher previous note u lower previous note d thus input converted string three letter alphabet u d example introductory theme beethoven th symphony would converted sequence d u d first note ignored previous pitch accomplish conversion sequence pitches melody must isolated tracked straight forward sounds however still considerable controversy exactly pitch general concept pitch clear given note pitch frequency closely matches hear performing conversion computer become troublesome intricacies human hearing still understood instance play th th th harmonics fundamental frequency actually hear fundamental frequency harmonics even though fundamental frequency present phenomenon first discovered schouten pioneer investigations carried schouten studied pitch periodic sound waves produced optical siren fundamental hz canceled completely pitch complex tone however prior elimination fundamental since interested tracking pitch humming examined methods automatically tracking pitch human voice estimate pitch acoustic signal must first understand signal created requires forming model sound production source vibrations vocal cords voiced sounds caused consequence forces exerted laryngeal walls air flows glottis gap vocal cords hess describes model vocal cords proposed hirano purposes paper though sufficient know glottis repeatedly opens closes thus providing bursts air vocal tract vocal tract modeled linear passive transmission system transfer function h z add additional transfer function r z takes account radiation output impedance vocal tract approximately set zero neutral position vocal tract regarded uniform tube resonances vocal tract occur sound wavelengths l cm average value vocal tract length sound propagation speed c m frequencies resonances frequencies f k called formant frequencies resulting sound hear considered convolution excitation pulse created glottis formant frequencies therefore want model speech signal start train excitation pulses shown figure formant frequencies use equation k gives formant frequencies f hz f hz f hz combining frequencies adding exponential envelope produces formant structure shown figure convolving train excitation pulses formant structure get synthesized pitch shown figure figure excitation signal used create synthesized pitch period train excitations making pitch hz figure formant structure created using hz hz hz formant frequencies figure synthesized pitch hz created convolving train excitation pulses spaced formant structure model human voice converted pitch prevalent view pitch hear pitch actually frequency bursts air occur track bursts air find pitch segment tracking pitch tried three methods tracking pitch autocorrelation maximum likelihood cepstrum analysis autocorrelation autocorrelation one oldest classical pitch trackers autocorrelation isolates tracks peak energy levels signal measure pitch referring back figure see signal n peaks impulses occur therefore tracking frequency peaks give us pitch signal order get frequency peaks employ autocorrelation defined unfortunately autocorrelation subject aliasing picking integer multiple actual pitch computationally complex found implementation autocorrelation require approximately seconds seconds khz bit audio mhz pentium workstation maximum likelihood maximum likelihood modification autocorrelation increases accuracy pitch decreases chances aliasing unfortunately computational complexity method makes autocorrelation look blindingly fast straight forward implementation matlab takes approximately one hour evaluate seconds audio mhz pentium workstation optimizations improved performance approximately minutes per seconds audio still far slow purposes therefore discarded method detailed explanation method reader may refer cepstrum analysis cepstrum analysis definitive classical method pitch extraction explanation reader directed oppenheim schafer original work compact form found method give accurate results humming output methods construed sequence frequency estimations successive pitches input convert estimates three step contour representation comparing estimated pitch previous one system adjacent pitches considered within quarter step equal tempered musical scale parameter adjustable analyzing costs benefits methods decided use modified form autocorrelation implementation searching database described user input hummed tune converted string letter alphabet discuss method searching audio database method searching database simple songs database preprocessed convert melody stream u d characters converted user input key compared songs pattern matching uses fuzzy search allow errors within matches errors reflect inaccuracies way people hum well errors representation songs performing key search within database need efficient approximate pattern matching algorithm approximate mean algorithm able take account various forms errors figure summarizes various forms errors anticipated typical pattern matching scheme figure three forms anticipated errors one mismatch algorithm adopted purpose described baesa yates perleberg algorithm addresses problem string matching k mismatches problem consists finding instances pattern string p p p p pm text string tn k mismatches characters instance p k mismatches simple string matching problem solvable o n time k m every substring length m qualifies match since every character p mismatched errors figure corresponds k worth mentioning several algorithms developed address problem approximate string matching running times ranged o mn brute force algorithm o kn o n log m algorithm adopted offers better performance average cases algorithms worst case algorithm occurs p key consists m occurrences single distinct character contour representation song consists n instances character case running time o mn however neither common useful situation purposes average case alphabet character equally likely occur running time size alphabet database incorporates key searching scheme using pattern matching techniques explained envisioned following design goals database given query database returns list songs ranked well matched query one best match number matches database retrieve depends upon error tolerance used key search error tolerance could set one two possible ways either user definable parameter database determine parameter based example heuristics depends length key design gives user opportunity perform queries even user sure notes within tune results query user identify song interest list large user perform new query restricted search list consisting songs retrieved consequence scheme user identify sets songs contain similar melodies evaluation section describes results experimental evaluation system evaluation tested tolerance system respect input errors whether mistakes user humming problems pitch tracking robustness effectiveness method directly related accuracy pitches hummed tracked accuracy melodic information within database ideal circumstances achieve close accuracy tracking humming ideal circumstances mean user places small amount space note hits note strongly purpose humming short notes encouraged even ideal user aspirate notes much possible perhaps going far voice vowel haaa haaa haaa currently experimented male voices evaluation database currently contains total songs song converted public domain general midi sources melodies different musical genres included including classical popular music simple heuristics used cut amount irrelevant information data e g midi channel ignored reserved percussion general midi standard however database still contains great deal information unrelated main theme melody even limitation discovered sequences pitch transitions sufficient discriminate songs consequence using fast approximate string matching algorithm search keys matched portion melody rather beginning size database grows larger however may prove advantage performance version pitch tracker using modified form autocorrelation takes seconds sparc workstation process typical sequences hummed notes brute force search database unsurprisingly shows linear growth size database remains seconds songs sparc therefore search time currently effectively limited efficiency pitch tracker contour representations song currently stored separate files opening closing files becomes significant overhead performance could improved packing songs one file using database manager plan modularize code make independent particular database schema future directions related work plan improve performance speed robustness pitch tracking algorithm using cubic spline wavelet cubic spline wavelet peaks discontinuities signal e air impulses one significant features wavelet analysis computed o n time currently pitch tracker slowest link system using wavelets purpose obvious advantages pattern matching algorithm present form discriminate various forms pattern matching errors discussed earlier accounts collectively forms errors may common others depending upon way people casually hum different tunes example drop errors reflected dropped notes tunes common transposition duplication errors tuning key search tolerant drop errors example may yield better results melodic contours source songs currently generated automatically midi data convenient optimal accuracy less redundant information could obtained entering melodic themes particular songs hand research standpoint interesting question extract melodies complex audio signals finally would like characterize improvement gained increasing resolution relative pitch differences considering query alphabets three five possible relationships adjacent pitches early experiments using alphabet five relative pitch differences higher much higher lower much lower verified changes sort promising one drawback introducing resolution user must somewhat accurate intervals actually hum explore various tradeoffs involved important issue precisely draw line notes little higher previous note much higher previous work efficiently searching database melodies humming seems limited mike hawley briefly discusses method querying collection melodic themes searching exact matches sequences relative pitches input midi keyboard incorporated approximate pattern matching implementing actual audio database midi songs significantly allowing queries hummed kageyama takashima published paper retrieving melodies using hummed melody japanese journal unable locate translated version footnotes terms vocal folds vocal chords less used synonyms literature modifications include low pass filtering center clipping described sondhi paper help eliminate formant structure generally causes difficulty autocorrelation based pitch detectors references ricardo baesa yates chris h perleberg fast practical approximate string matching combinatorial pattern matching third annual symposium pages ricardo baesa yates g h gonnet fast string matching mismatches information computation stephen handel listening introduction perception auditory events mit press michael jerome hawley structure sound phd thesis mit september wolfgang hess pitch determination speech signals springer verlag berlin heidelberg m hirano structure vibratory behavior vocal folds m sawashima f cooper editors dynamic aspects speech production pages university tokyo press l r rabiner j j dubnowski r w schafer real time digital hardware pitch detector ieee transactions acoustics speech signal processing assp feb kageyama y takashima melody retrieval method hummed melody language japanese transactions institute electronics information communication engineers d ii j d ii august g landau u vishkin efficient string matching k mismatches theoretical computer science v oppenheim speech analysis synthesis system based homomorphic filtering j acoustical society america february alan v oppenheim ronald w schafer discrete time signal processing prentice hall englewood cliffs nj r plomp aspects tone sensation academic press london m m sondhi new methods pitch extraction ieee trans audio electroacoust special issue speech communication processing part ii au june james d wise james r caprio thomas w parks maximum likelihood pitch estimation ieee trans acoustics speech signal processing october