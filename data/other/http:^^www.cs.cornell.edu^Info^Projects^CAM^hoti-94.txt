mime version server cern date monday nov gmt content type text html content length last modified sunday apr gmt low latency communication atm networks using active messages low latency communication atm networks using active messages thorsten von eicken veena avula anindya basu vineet buch department computer science cornell university ithaca ny abstract recent developments communication architectures parallel machines made significant progress reduced communication overheads latencies order magnitude compared earlier proposals paper examines whether techniques carry clusters workstations connected atm network even though clusters use standard operating system software equipped network interfaces optimized stream communication allow direct protected user level access network use networks without reliable transmission flow control first part paper describes differences communication characteristics clusters workstations built standard hardware software components state art multiprocessors lack flow control operating system coordination affects communication layer design significantly requires larger buffers end multiprocessors second part evaluates prototype implementation low latency active messages communication model sun workstation cluster interconnected atm network measurements show application application latencies microseconds small messages roughly comparable active messages implementation thinking machines cm multiprocessor table contents introduction technical issues ssam sparcstation active messages prototype comparison approaches conclusions bibliography introduction shift slow broadcast based local area networks high bandwidth switched network architectures making use clusters workstations platforms parallel processing attractive number software packages already support parallel processing today workstations networks communication performance two orders magnitude inferior state art multiprocessors result embarassingly parallel applications e parallel applications essentially never communicate make use environments networking technologies atm offer opportunity close gap example atm cells roughly size messages multiprocessors takes microseconds send receive cell atm switches configured p purely technical point view gap clusters workstations multiprocessors certainly closing distinction two types systems becoming blurred differences remain particular design construction multiprocessors allows better integration components designed fit together addition sharing physical components power supplies cooling cabinets potential reduce cost allow denser packaging debate significance technological differences still open becoming clear two approaches yield qualitatively similar hardware systems indeed possible take cluster workstations load system software making look almost identical multiprocessor means continuous spectrum platforms spanning entire range workstations ethernet state art multiprocessors become available tha pragmatic point view however significant differences likely remain important attraction using cluster workstations instead multiprocessor lies shelf availability major hardware software components means components readily available familiar cost lower economies scale leveraged across entire workstation user community thus even technical point view continuous spectrum clusters multiprocessors use shelf components clusters maintain differences fact use standard components clusters raises question whether reasonably used parallel processing recent advances multiprocessor communication performance principally due tighter integration programming models compilers operating system functions hardware primitives clear whether advances carried clusters whether use standard components squarely odds achieving level integration required enable modern parallel programming models specifically new communication architectures distributed shared memory explicit remote memory access active messages reduced costs hundreds thousands microseconds dozen precisely integration system components new communication architectures designed network interfaces implement common primitives directly hardware allow operating system moved critica paper examines whether techniques developed improve communication performance multiprocessors particular active messages carried clusters workstations standard networks mostly standard system software paper assumes current state art technology clusters using atm networks differ multiprocessors three major aspects clusters use standard operating system software implies less coordination among individual nodes particular respect process scheduling address translation atm networks provide reliable delivery flow control taken granted multiprocessor networks network interfaces workstations optimize stream communication e g tcp ip less well integrated overall architecture e g connect o bus instead memory bus comparing communication clusters multiprocessors paper makes two major contributions first analyzes section implications differences clusters multiprocessors design communication layers similar used multiprocessors second describes section design active messages prototype implementation collection sun workstations interconnected atm network yields application application latencies order us use active messages workstation clusters briefly contrasted approaches section section concludes paper technical issues collections workstations used many different forms run large applications order establish basis comparison multiprocessors paper limits consider collections workstations called clusters consist homogeneous set machines dedicated run parallel applications located close proximity machine room interconnected atm network cluster employed large variety settings cluster could simply provide high performance compute service user community run large parallel applications typical setting would computational resource distributed application one example stormcast weather monitoring system norway runs large collection machines spread across large portion country uses cluster dozen workstations machine room without high speed network case run compute intensive weather prediction models emit storm warnings availability low latency communication among workstations would enable use parallel programming languages powerful parallel algorithms require closer coupling among processors possible today concentrating compute cluster offers largest potential improvement latency long haul links dominated speed light network congestion issues wide area communication comparatively better served today distributed computing software note paper argue running concurrent applications heterogeneous environment across large distances workstations happen sitting idle interesting design point fact used successfully set communication issues occurring context cannot compared multiprocessor given applications clusters considered exhibit characteristics similar multiprocessors programming models used would comparable identical popular parallel computing includes various forms message passing e g send receive pvm shared memory e g cache coherent shared memory remote reads writes explicit global memory parallel object oriented languages e g numerous c extensions parallel machines several proposed communication architectures achieved low overheads low latencies high bandwidths required high performance implementations programming models particular cache coherent shared memory remote reads writes active messages offer round trip communication within hundred instruction times frequent communication fine granularity object object cache line basis remains compatible high performance settings overhead communication time spent processor initiating communication essentially cost pushing message data network interface sending end pulling receiving end virtually cycles spent protocol handling reliability flow control handled hardware operating system need involved every communication operation network interface hardware enforce protection boundaries across network communication architectures cannot moved straightforward manner multiprocessors clusters workstations atm networks three major differences two atm networks offer neither reliable delivery flow control atm network interfaces provide support protected user level access network workstation operating systems coordinate process scheduling address translation globally coping differences poses major technical challenges may eventually require integration multiprocessor specific features clusters following three subsections present nature differences detail discuss resulting issues reliability flow control network multiprocessor networks flow control implemented hardware link link basis whenever input buffer router fills output stream router disabled prevent buffer overflow flow control thus effect blocking messages network eventually back pressure propagates sending nodes prevented injecting messages mechanism guarantees messages never dropped due buffer space limitations within network receiving end addition electrical characteristics network designed ensure low error rates use simple error detection correction mechanism implemented hardware offer reliability within network typical processing nodes contrast atm network provide form flow control offer reliable delivery instead higher protocol layers must detect cell loss corruption cause retransmission partitioning responsibilities may acceptable case stream based communication e g tcp ip video audio questionable parallel computing setting flow control error detection correction multiprocessor networks serve cover four causes message loss buffer overflow receiving software buffer overflow receiving network interface buffer overflow within network message corruption due hardware errors atm network simple window based end end flow control schemes per message crc used aal cover first last cases cell loss addition preventing buffer overflow receiving network interface achieved ensuring rate cells moved interface main memory least large maximal cell arrival rate preventing buffer overflow within network however realistically possible using end end flow control particularly problem parallel computing setting nodes tend communicate nodes highly regular irregular patterns unpredictable intervals degree contention within network therefore cannot measured predicted accuracy either sender receiver communication patterns result high contention result high cell loss rates causing extensive retransmissions traditional flow control schemes used stream based communication avoid fruitless retransmission storms dynamically reducing transmission rate connections experience high cell loss rates works settings following law large numbers contention wide area network tend vary instantaneously therefore degree contention observed recent past good predictor contention near future illustration difficulties parallel computing setting consider implementation parallel sort efficient parallel sort algorithms based alternation local sorts nodes permutation phases nodes exchange data nodes permutation phases serve move elements sorted towards correct position communication patterns observed highly dynamic characteristics depend large degree input data point attempted data rate given node exceeds link rate output buffers stream switches start filling communication patterns change rapidly essentially every cell futile attempt predict contention given communication pattern probability internal contention among seemingly unrelated connections high beyond problems caused contention resulting retransmissions lack reliable delivery guarantee atm networks imposes certain overhead communication primitives specifically sender must keep copy cell sent corresponding acknowledgment received case cell must retransmitted means messages cannot transferred directly processor registers network interface possible cm rather memory copy must made well user level access network interface recently multiprocessor communication architectures achieved significant reduction communication overhead eliminating operating system critical path order compromise security network interface must offer form protection mechanism shared memory models memory management unit extended map remote memory local virtual user address space operating system enforce security managing address translation tables message based network interfaces contain node address translation table maps user virtual node numbers onto physical node address space operating system enforces security controlling address translation thereby preventing process sending message arbitrary node current generation message based network interfaces control destination node address therefore require processes parallel program run time next generation adds sending process id message allowing receiving network interface discriminate messages destined currently running process retrieve message directly messages dormant processes must queued typically operating system later retrieval contrast network interfaces available workstations yet incorporate form protection mechanism instead operating system must involved sending reception every message connection based nature atm networks would principally allow design protection mechanism limit virtual circuits user process access operating system would still control virtual circuit set architecture networking layers current operating systems seem set allow user level network interface access appears unlikely network interfaces features become commonplace soon challenge high performance communication layer clusters thus minimize path kernel judiciously coordinating user kernel interactions coordination system software across communicating nodes almost communication architectures message reception logic critical performance bottleneck order able handle incoming messages full network bandwidth processing required arriving message must minimized carefully trick used multiprocessor systems ensure rapid message handling constrain sender send messages easy handle shared memory systems done coordinating address translation tables among processing nodes originating node translate virtual memory address remote access directly place corresponding physical memory address message set communication primitives small fixed e g read write forcing sender perform complicated part remote memory access namely protection checks address translation handling request relatively simple implement virtual address sent receiving node could discover requested virtual memory location paged disk result handling message would become rather involved active messages multiprocessors scheduling processes assumed coordinated among nodes communicating processes execute simultaneously respective nodes guarantees messages handled immediately arrival destination process order accomplish sender active message specifies user level handler destination whose role extract message network integrate ongoing computation handler also implement simple remote service send reply active message back however order prevent deadlock communication patterns limited requests replies e g handler reply message allowed send messages implementation active messages typically reserves first word message handler address handler receiving end dispatched immediately message arrival dispose message fact message layer call upon handlers deal messages fifo order simplifies buffering considerably required traditional message passing models pvm mpi nx models allow processes consume messages arbitrary order arbitrary times forcing communication architecture implement general buffer message matching mechanisms high cost clusters fact operating systems individual nodes nearly coordinated contradicts assumption messages always consumed quickly upon arrival case active messages destination process might suspended cannot run handler shared memory model memory location requested might mapped although exact coordination possible without major changes operating system core implementation either communication model likely able perform coordination among nodes influence local operating system accordingly may allow communication layer assume common case everything works fine must able handle difficult cases well summary even though superficially cluster workstations appears technically comparable multiprocessor reality key characteristics different cause significant implementation difficulties comparable raw hardware link bandwidths bisection bandwidths routing latencies conceal lack clusters flow control reliability user level network access operating system coordination shortcomings inevitably result lower communication performance quantitative effect performance evaluated next section presents prototype implementation active messages cluster sun workstations however lack flow control atm networks poses fundamental problem catastrophic performance degradation occur due significant cell loss particular communication patterns ssam sparcstation active messages prototype ssam prototype implements critical parts active messages communication architecture cluster sparcstations connected atm network primary goal evaluate whether possible provide parallel programming environment cluster comparable found multiprocessors prototype primarily concerned providing performance par parallel machines addressing handicaps atm networks identified previous section particular prototype provides reliable communication evaluate cost performing necessary flow control error checking software minimizes kernel intervention determine cost providing protection software buffering designed tolerate arbitrary context switching nodes time limited experimental set described available prototype cannot provide information neither cell losses due contention within network affect performance scheduling processes coordinated improve overall performance parallel applications active messages communication architecture active messages communication architecture offers simple general purpose communication primitives thin veneer raw hardware intended serve substrate building libraries provide higher level communication abstractions generating communication code directly parallel language compiler unlike communication layers intended direct use application programmers really provides lower level services communication libraries run time systems built basic communication primitive message associated small amount computation form handler receiving end typically first word active message points handler message message arrival computation node interrupted handler executed role handler get message network integrating ongoing computation sending reply message back buffering scheduling provided active messages extremely primitive thereby fast buffering involved actual transport scheduling required activate handler sufficient support many higher level abstractions general buffering scheduling easily constructed layers active messages needed minimalist approach avoids paying performance penalty unneeded functionality order prevent deadlock livelock active message restricts communication patterns requests replies e handler request message allowed send reply message reply handler allowed send replies ssam functionality current implementation geared towards sending small messages fit payload single atm cell eight available bytes payload atm cell used ssam hold flow control information bits handler address bits aal compatible checksum bits remaining bytes hold active message data c header file interface ssam shown figure send request active message user places message data per connection buffer provided ssam calls ssam connection identifier remote handler address ssam adds flow control information traps kernel message injected network also polls receiver processes incoming messages receiving end network polled ssam ssam poll latter polls network messages accumulated receive fifo moved buffer ssam calls appropriate handler message passing arguments originating connection identifier address buffer holding message address buffer reply message handler processes message may send reply message back placing data buffer provided returning address reply handler null reply sent figure c interface sparcstation active messages current prototype use interrupts instead network polled every time message sent means long process sending messages also handle incoming ones explicit polling function provided program parts communicate using interrupts planned implemented yet example implementing remote read ssam sample implementation split phase remote double word read shown figure readdouble function increments counter outstanding reads formats request active message address read well information reply sends message readdouble h handler fetches remote location sends reply back readdouble rh reply handler stores data memory decrements counter originating processor waits completion read busy waiting counter end readdouble split phase read could constructed easily exposing counter caller could proceed computation initiating read wait counter data required figure sample remote read implementation using ssam experimental set experimental set used evaluate performance prototype ssam implementation consists mhz sparcstation mhz sparcstation running sunos two machines connected via fore systems sba atm interfaces using mb taxi fiber interfaces located sbus bit o bus running mhz provide cell deep output fifo well cell input fifo send cell processor stores bytes memory mapped output fifo receive cell reads bytes input fifo register interface indicates number cells available input fifo note network interface used much simpler closer multiprocessor nis second generation atm interfaces available today function performed hardware beyond simply moving cells onto fiber checksum generation checking atm header aal compatible payload particular dma segmentation reassembly multi cell packets provided ssam implementation implementation sparcstation atm active messages layer consists two parts device driver dynamically loaded kernel user level library linked applications using ssam driver implements standard functionality open close atm device provides two paths send receive cells fast path described consists three trap instructions lead directly code sending receiving individual atm cells traps relatively generic functionality specific active messages user level library also performs flow control buffer management conventional read write system call interface provided comparison purposes allows send receive cells using pure device driver approach traps send receive cells consist carefully crafted assembly language routines routine small instructions send receive traps respectively uses available registers carefully register usage simplified sparc architecture use circular register file provides clean register window trap interfacing program traps via function call arguments passed another registers become available trap following paragraphs describe critical parts ssam implementation detail flow control simple sliding window flow control scheme used prevent overrun receive buffers detect cell losses window size dimensioned allow close full bandwidth communication among pairs processors order implement flow control window size w process pre allocates memory hold w cells per every process communicates algorithm send request message polls receiver free window slot available injects cell network saving one buffers well case retransmitted upon receipt request message message layer moves cell buffer soon corresponding process running calls active message handler handler issues reply sent copy held buffer handler generate reply explicit acknowledgment sent upon receipt reply acknowledgment buffer holding original request message reused note distinction requests replies made active messages allows acknowledgments piggy backed onto replies recovery scheme used case lost duplicate cells standard except reception duplicate request messages may indicate lost replies retransmitted important realize flow control mechanism really attempt minimize message losses due congestion within network lack flow control atm networks effectively precludes simple congestion avoidance scheme larger test beds become available atm community agrees routers handle buffer overflows seems futile invest sophisticated flow control mechanisms nevertheless bursty nature parallel computing communication patterns likely require solution performance characteristics atm network become robust multiprocessor networks user kernel interface buffer management streamlining user kernel interface important factor contributing performance ssam prototype kernel preallocates buffers process device opened pages pinned prevent page outs mapped using mmap processes address space every message send user level library chooses buffer next message places pointer exported variable application program moves message data buffer passes connection id handler address ssam finishes formatting cell adding flow control handler traps kernel trap passes message offset within buffer area connection id registers kernel protection ensured simple masks limit connection id offset ranges lookup maps current process connection ids virtual circuit kernel finally moves cell output fifo receiving end read atm kernel trap delivers batch incoming cells pre determined shared memory buffer number cells received returned register cell kernel performs four tasks loads first half cell registers uses vci index table obtain address appropriate processes input buffer moves full cell buffer checks integrity cell using three flag bits set ni last byte upon return trap ssam library loops received cells checking flow control information calling appropriate handlers request reply messages sending explicit acknowledgments needed ssam performance following paragraphs describe performance measurements ssam made number synthetic benchmarks following terminology used overhead consists processor cycles spent preparing send receive message latency time message send routine called time message handled remote end bandwidth rate user data transferred performance goal ssam fiber rate mbit transmits cell every us bytes atm payload bandwidth mb atm traps detailed cost breakdown operations occurring traps send receive cells shown table two timing columns refer measurements taken sparcstation sparcstation respectively times obtained measuring repeated executions trap gettimeofday uses microsecond accurate clock takes us ss time break trap measured commenting appropriate instructions somewhat approximate due pipeline overlap occurring successive instructions table cost breakdown traps send receive cells operation ss ss write trap trap rett us us check pid con us us nection id addt l kernel ovhd us us load cell push us us push cell ni us us total us us read trap trap rett us us check cell count us us addt l kernel ovhd us us per cell pull ni us us per cell demux us us per cell store away us us total cell us us per cell total us us cells write read trap total cells read us us total cell read us us null system call us us write trap cost broken parts cost trap return protection checks overhead fetching addresses loading cell registers pushing cell network interface ss numbers show clearly fiber saturated sending cell time user level also indicates majority cost lies access network interface across sbus cost trap surprisingly low even though second largest item fact could reduced slightly current implementation adds level indirection trap dispatch simplify dynamic loading device driver read trap itemized similarly cost trap return fetching device register count available cells additional overhead setting addresses loading cell network interface demultiplexing among processes storing cell away total cost shows trap receives single cell well per cell cost trap receives cells access device dominates due fact double word load incurs full latency sbus access total time us ss falls short fiber cell time limit achievable bandwidth fiber write read trap first sends cell receives chunk cells amortizes cost trap across functions overlaps checking cell count slightly sending last item table shows cost null system call comparison purposes write file descriptor used clear system call approach would yield performance far inferior traps would achieve fraction fiber bandwidth atm read write system calls addition direct traps device driver allows cells sent received using traditional read write system calls device file descriptor time conventional path provided comparison purposes read write entry points device driver limited sending receiving single cells multi cell reads writes could supported easily read write entry points perform following operations check appropriateness file descriptor transfer data user space internal buffer using uiomove transfer data internal buffer fifos network interface internal buffer used data cannot transferred directly user space device using uiomove due fact device fifos word addressable use internal buffer also allows double word accesses device fifos improves access times considerably table shows costs various parts read write system calls syscall overhead entries reflect time taken read respectively write system call empty read write device driver routine measures kernel overhead associated system calls check fd uiomove entry reflects time spent checking validity file descriptor performing uiomove case read also includes time check device register holding number cells available input fifo push pull cell entries reflect time spent transfer contents one cell internal buffer device fifos write read cell totals reflect cost full system call read cells entry time taken unsuccessful poll includes system call overhead file descriptor checks reading receive ready register table cost sending receiving cells using read write system calls operation ss ss write system call syscall overhead us us check fd uiomove us us push cell ni us us write total us us read system call syscall overhead us us pull cell ni us us check fd recv ready us us uiomove read total cell us us read total cells us us timings show clearly overhead read write system call interface prohibitive small messages larger messages however may well viable choice portable traps ssam measurements active messages layer built cell send receive traps shown table cases one word active message payload carries data handlers simply return send request uses write read trap adds little us overhead ss cell formatting flow control handling times roughly cost read trap reading cells per trap plus little us flow control handler dispatch reply sent adds time write trap table cost breakdown sparcstation active messages operation ss ss send request us us handle request reply us us sent handle request send us us reply handle ack us us handle reply us us measurements show supporting single cell active messages optimal longer messages required achieve peak bulk transfer rates one cell time prototype yield mb simpler interface shorter messages e g bytes payload might well useful well accelerate small requests acknowledgments often found higher level protocols unfortunately given trap cost dominated network interface access time sba requires bytes cell transferred processor unlikely significant benefit realized split c full implementation split c still progress timings remote memory access primitives show round trip time remote read double word aligned bytes takes us ss one way remote store takes us payload remote accesses smaller payloads noticeably cheaper bulk write implemented current ssam layer transfers mbytes experiments show using long messages could improved mbytes using full atm payload simplifying handling slightly unresolved issues current ssam prototype influence kernel process scheduling given current buffering scheme ssam layer operation influenced process running performance applications however likely highly influenced scheduling best influence scheduler semi portable fashion requires investigation promising approach appears use real time thread scheduling priorities available solaris amount memory allocated ssam prototype somewhat excessive fact simplicity current prototype uses twice many buffers strictly necessary example assuming flow control window cells used kernel allocates pins kbytes memory per process per connection node cluster parallel applications running represents mb memory per processor number preallocated buffers could reduced without affecting peak bulk transfer rates adjusting flow control window size dynamically idea first cell long message contain flag requests larger window size receiver extra buffers would allocated purpose receiver grants larger window one sender time using first acknowledgment cell bulk transfer larger window size remains effect end long message scheme two benefits request larger window overlapped first cells long message receiver prevent many senders transferring large data blocks simultaneously would sub optimal cache however fundamentally appears memory alternatively low performance price pay neither flow control network coordinated process scheduling subtle problem atm payload alignment used sba interface surface future bytes atm cell padded sba bytes byte payload starts th byte e half word aligned effect bulk transfer payload formats designed sba mind supporting double word moves data memory sba clash network interfaces double word align atm payload summary prototype active messages implementation sparcstation atm cluster provides preliminary demonstration communication architecture developed multiprocessors adapted peculiarities workstation cluster performance achieved roughly comparable multiprocessor cm one way latency roughly us clear without network interface closer processor performance gap cannot closed time taken flow control protection software surprisingly low least comparison network interface access times cost effect shifted large pre allocated pinned buffers prototype memory usage somewhat excessive schemes comparable performance also require large buffers overall ssam speed comes careful integration layers language level kernel traps key issues avoiding copies application place data directly kernel picks move device passing easy check information kernel particular pass arbitrary virtual address comparison approaches atm network communication layer directly comparable ssam remote memory access model proposed thekkath et al implementation similar ssam uses traps reserved opcodes mips instruction set implement remote read write instructions major difference two models remote memory operations separate data control transfer active messages unifies remote memory accesses data transferred user memory kernel without corresponding process run model used allow remote reads writes full address space process rather communicating process must allocate special communication memory segments pinned operating system buffers used ssam communication segments flexible ssam buffers directly hold data structures limited fact segments pinned advantage ssam remote memory accesses coupling data control message causes small amount user code executed allows data scattered complex data structures scheduling computation directly influenced arrival data remote memory access model limited control transfer offered per segment notification flags order cause file descriptor become ready finally ssam provides reliable transport mechanism remote memory access primitives unreliable provide flow control table compares performance two approaches thekkath implementation uses two decstation interconnected turbochannel version fore atm interface used ssam performs little worse ssam data transfer significantly worse control transfer remote reads writes directly comparable transfer payload per cell table comparison ssam remote memory accesses decstation sover atm operation ssam remote mem access read latency us us write latency us us addt l control none us transfer ovhd block write mb mb performance traditional communication layers atm network evaluated lin et al shows two orders magnitude higher communication latencies ssam offers table summarizes best round trip latencies one way bandwidths attained sun sparcstation connected fore sba interfaces without switch millisecond scale reflects costs traditional networking architecture used layers although clear fore aal api slower read write system call interface described note tcp ip implementation well optimized fast path yield sub millisecond latencies table performance traditional communication layers sun sparcstation atm communication layer round trip peak latency bandwidth fore aal api ms mb bsd tcp ip sockets ms mb pvm tcp ip ms mb sun rpc ms mb conclusions emergence high bandwidth low latency networks making use clusters workstations attractive parallel computing style applications technical point view continuous spectrum systems conceived ranging collections ethernet based workstations tightly integrated custom multiprocessors however paper argues clusters characterized use shelf components handicap respect multiprocessors hardware software customized allow tighter integration network overall architecture use standard components particular atm networking technology results three major disadvantages clusters respect multiprocessors atm networks offer reliable delivery flow control ii current network interfaces well integrated workstation architecture iii operating systems nodes cluster coordinate process scheduling address translations prototype implementation active messages communication model described paper achieves two orders magnitude better performance traditional networking layers table shows resulting communication latencies bandwidths ball park state art multiprocessors key success use large memory buffers careful design lean user kernel interface major obstacle towards closing remaining performance gap slow access network interface across o bus reducing buffer memory usage requires coordination process scheduling across nodes taking care flow control software dominate performance study behavior atm networks parallel computing communication loads remains open question table comparison ssam performance recent parallel machines machine peak round trip bandwidth latency sp mpl p mb us paragon nx mb us cm active mb us mesg ss cluster mb us ssam bibliography ccitt recommendation b isdn atm functional characteristics revised version geneva itu d e culler dusseau c goldstein krishnamurthy lumetta von eicken k yelick introduction split c proc supercomputing d e culler dusseau r martin k e schauser fast parallel sorting logp split c proc wppp july von eicken d e culler c goldstein k e schauser active messages mechanism integrated communication computation proc th isca pages may geist beguelin j dongarra w jiang r manchek v sunderam pvm user guide reference manual oak ridge national laboratory technical report ornl tm february k li p hudak memory coherence shared virtual memory systems acm transactions computer systems november m lin j hsieh d h c du j p thomas j macdonald distributed network computing local atm networks ieee journal selected areas communications special issue atm lans appear p pierce g regnier paragon implementation nx message passing interface proc shpcc may c b stunkel d g shea d g grice p h hochschild m tsao sp high performance switch proc shpcc may c thekkath h m levy e d lazowska efficient support multicomputing atm networks university washington technical report april c thekkath h m levy e d lazowska separating data control transfer distributed operating systems proc th int l conf asplos appear october thinking machines corporation cambridge massachusetts connection machine cm technical summary november footnotes term cluster used refer collections workstation class machines interconnected low latency high bandwidth network paper focuses exclusively scalable multiprocessor architectures specifically excludes bus based shared memory multiprocessors current atm switches latencies order magnitude higher comparable multiprocessor networks however difference seem inherent atm networks least local area switches discussion differences fault isolation characteristics beyond scope paper although transmission media may cause burst errors beyond correction capabilities crc codes cache coherent shared memory stretch characterization given cache receiving node essentially performs another address translation may miss require additional communication nodes complete request bandwidths measured megabytes per second kernel write protects trap vectors boot ssam prototype uses permanently loaded trap performs indirect jump via kernel variable allow simple dynamic driver loading note realistic setting fore asx switch add roughly us latency write time us round trip read time one could easily describe traps employed ssam additional emulated communication instructions