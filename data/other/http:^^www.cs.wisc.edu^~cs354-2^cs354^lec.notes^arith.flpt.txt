date tue nov gmt server ncsa content type text html last modified wed aug gmt content length lecture notes chapter floating point arithmetic chapter floating point arithmetic floating point arithmetic arithmetic operations floating point numbers consist addition subtraction multiplication division operations done algorithms similar used sign magnitude integers similarity representation example add numbers sign numbers opposite sign must subtraction addition example decimal value given scientific notation x x first step align decimal points second step add x x x presumes use infinite precision without regard accuracy third step normalize result already normalized example fl pt value given binary add fl pt representations step align radix points shifting mantissa left bit decreases exponent shifting mantissa right bit increases exponent want shift mantissa right bits fall end come least significant end mantissa choose shift since want increase exponent shift places original value shifted place note hidden bit shifted msb mantissa shifted places shifted places shifted places shifted places shifted places shifted places shifted places step add forget hidden bit step normalize result get hidden bit already example result subtraction like addition far alignment radix points algorithm subtraction sign mag numbers takes subtracting compare magnitudes forget hidden bit change sign bit order operands changed forget normalize number afterward multiplication example decimal values given scientific notation x x algorithm multiply mantissas add exponents x x x example binary use mantissa bits spend day multiplication part x mantissa multiplication forget hidden bit x becomes add exponents always add true exponents otherwise bias gets added twice biased switch order subtraction get negative value true exp true exp add true exponents re bias exponent unsigned representation put result back together add sign bit normalize result moving radix point one place left increases exponent becomes value stored hidden bit division similar multiplication true division unsigned division mantissas forget hidden bit subtract true exponents ieee standard specific done unfortunately hardware pretty slow comparisons approximate times complement integer add time unit fl pt add time units fl pt multiply time units fl pt divide time units faster way division called division reciprocal approximation takes time fl pt multiply unfortunately results always true division division reciprocal approximation instead b x b figure reciprocal b use fl pt multiplication hardware example result isn true division true division exactly reciprocal approx x always possible get perfectly accurate reciprocal issues floating point note discussion touches surface issues people deal entire courses could probably taught issues rounding arithmetic operations fl pt values compute results cannot represented given amount precision must round results many ways rounding correct uses exist different reasons goal computation computer round end result correct possible even arguments really correct lecture note number line help get message across methods rounding round toward also called truncation figure many bits digits available take many bits digits result throw away rest effect making value represented closer example decimal places available decimal places available round toward infinity regardless value round towards infinity example decimal places decimal places round toward infinity regardless value round towards infinity example decimal places decimal places binary round toward infinity round toward infinity round toward zero truncate round toward nearest odd case anything right number digits kept rounded ieee standard least significant bit kept zero odd case way odd case note bit different round nearest algorithm tie case learned elementary school decimal numbers use standards allows machines following standard exchange data calculate exact results ieee fl pt standard sets parameters data representation bits mantissa vs exponent mips architecture follows standard overflow underflow integer arithmetic floating point arithmetic operations cause overflow detection overflow fl pt comes checking exponents normalization overflow occurred infinity value represented propagated calculation underflow occurs fl pt representations number small close represented show number line fl pt value cannot normalized getting left radix point would cause exponent field underflow occurs hw vs sw computing floating point operations done hardware circuitry software program code programmer won know occuring without prior knowledge hw sw much slower hw approx times difficult good exercize students would design sw algorithm fl pt addition using integer operations sw fl pt operations tedious takes lots shifting masking get data right form use integer arithmetic operations get result shifting masking put number back fl pt format common thing manufacturers offer versions architecture one hw sw fl pt ops