date tue nov gmt server apache dev connection close content type text html last modified tue sep gmt etag d cd c c content length accept ranges bytes vision touch guided manipulation vision touch guided manipulation group mit artificial intelligence lab nonlinear systems lab vision touch guided manipulation group mit artificial intelligence lab conducts research wide variety topics related manipulator end effector design dextrous manipulation adaptive nonlinear control vision guided manipulation employ techniques various fields including mechanical design stability theory machine learning approximation theory computer vision group headed dr kenneth salisbury mechanics professor jean jacques e slotine autonomy vision groups mit ai lab headed ken haptic interfaces group robot hands group professor slotine also heads nonlinear systems laboratory people associated vision touch guided manipulation group brian anthony touch sensing mark cannon wavelet networks graduated brian eberman system integration graduated brian hoffman active vision w jesse hong coordination vision manipulation akhil madhani wrist hand mechanism g uumlnter niemeyer adaptive control system integration daniel theobald visual processing ichiro watanabe machine learning introduction robots research references introduction robots whole arm manipulator mit whole arm manipulator wam arm fast force controllable robot arm designed dr salisbury group ai lab concept whole arm manipulation originally aimed enabling robots use surfaces manipulate perceive objects environment central concept group design efforts general focus controlling forces interaction robots environment permit wam arm employs novel cable transmissions stiff low friction backdrivable turn permits lightweight design achieve good bandwidth force control contact environment arm design maximizes lowest resonant frequency system employs impedance matching ratio motor arm masses also enables arm achieve high accelerations moving free space prof slotine students developed system architectures control algorithms force controlled tasks tasks requiring rapid accurate free space motion algorithms also provide fast stable adaptation arm large variations loads environments talon new wrist hand mechanism developed replaces previous forearm mounted system new wrist hand known talon provides additional powered freedoms one grasping forces two orientation motors device located forearm minimize end effector mass maximize workspace grasping mechanism comprised group fingers move group fingers two groups may made mesh together encircling objects finger inner surfaces serrated provide high contact friction rough rock surfaces curved enhance capturing large small objects fingers may deflect compliantly accomodate object geometry finger deflections may sensed provide monitoring grasp state also studied design miniature end effector suitable grasping small rocks cylindrical objects similar spirit talon new miniature end effector utilizes slightly different kinematics enlarge feasible grasping volume fast eye gimbals recent component system active vision system comprised two hi resolution color ccd cameras mm focal length lenses mounted two degree freedom gimbals utilized cameras narrow field view give higher resolution images typical objects implies however cameras actuated order pan tilt cover broad scenes leading active vision system associated trade controller precision image resolution narrowness field view actuators implemented designed lab known fast eye gimbals fegs fegs provide directional positioning cameras using similar drive mechanism wam two joints cable driven ranges motion degrees degrees base upper joint axes respectively two fegs currently strategically mounted ceiling rafters wide baseline higher position accuracy using stereo vision methods independent nature fegs allow us position one different locations order vary baseline orientation coordinate frame well easily add additional cameras provide additional perspectives introduction robots research references research projects robust grasping unstructured environments one current projects funded nasa jpl develop fundamental understanding problem combining real time vision touch sensor data robot control yield robust autonomous semi autonomous grasping grasp stabilization research focused providing conceptual experimental support planned going nasa missions utilizing earth orbiting planetary surface robotics implemented high speed active vision system multi processor operating system basic algorithms acquisition grasp stationary spherical cylindrical objects using coordinated robotic vision touch sensing control preliminary experiments tracking moving objects also completed concurrently research integrated wrist hand design used performing sensor guided grasps preliminary design next generation miniature end effector completed robotic catching free flying objects another direction research funded fujitsu furukawa sloan foundation accomplish real time robust catching free flying objects currently focusing spherical balls various sizes also experimenting additional objects different dynamic characteristics sponge balls cylindrical cans paper airplanes system uses low cost vision processing hardware simple information extraction camera signal processed independently vision boards designed members mit ai laboratory cognachrome vision tracking system vision boards provide us center area major axis number pixels aspect ratio color keyed image two fast eye gimbals allow us locate track fast randomly moving objects using kalman like filtering methods assuming fixed model behavior motion independent tracking algorithms use least squares techniques fit polynomial curves prior object location data determine future path knowledge hand calculate path wam match trajectories object accomplish catching smooth object wam post catching deceleration addition basic least squares techniques path prediction study experimentally nonlinear estimation algorithms give long term real time prediction path moving objects goal robust acquisition algorithms based stable line construction approximation networks composed state space basis functions localized space spatial frequency initial step studied network performance predicting path light objects thrown air application may include motion prediction objects rolling bouncing breaking rough terrains recent successful results application network obtain catching sponge balls even paper airplanes click view wam catching click view wam airplane catching copy photo courtesy hank morgan introduction robots research references partial list references autonomous rock acquisition d theobald w j hong madhani b hoffman g niemeyer l cadapan j j e slotine j k salisbury proceedings aiaa forum advanced development space robotics madison wisconsin august experiments hand eye coordination using active vision w hong j j e slotine proceedings fourth international symposium experimental robotics iser stanford california june july robotic catching manipulation using active vision w hong m thesis department mechanical engineering mit september space frequency localized basis function networks nonlinear system estimation control m cannon j j e slotine neurocomputing adaptive visual tracking gaussian network algorithms robotic catching h kimura j j e slotine dsc vol advances robust nonlinear control systems winter annual meeting asme anaheim ca pp november experiments robotic catching b m hove j j e slotine proceedings american control conference vol boston ma pp june performance adaptive manipulator control g niemeyer j j e slotine international journal robotics research december preliminary design whole arm manipulation system wam j k salisbury w townsend b eberman d m dipietro proceedings ieee international conference robotics automation philadelphia pa april effect transmission design force controlled manipulator performance w townsend phd thesis department mechanical engineering mit april see also mit ai lab technical report whole arm manipulation j k salisbury proceedings th international symposium robotics research santa cruz ca august design control two axis gimbal system use active vision n swarup b thesis dept mechanical engineering mit cambridge ma high speed low latency portable vision sensing system wright spie september introduction robots research references maintainer jesse ai mit edu comments wam ai mit edu last updated mon aug edt jesse ai mit edu copy rights reserved