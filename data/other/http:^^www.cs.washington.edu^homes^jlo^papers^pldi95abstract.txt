date tue dec gmt server ncsa content type text html last modified tue oct gmt content length improving balanced scheduling compiler optimizations increase instruction level parallelism improving balanced scheduling compiler optimizations increase instruction level parallelism jack l lo susan j eggers traditional list schedulers order instructions based optimistic estimate load latency imposed hardware therefore cannot respond variations memory latency caused cache hits misses non blocking architectures contrast balanced scheduling schedules instructions based estimate amount instruction level parallelism program scheduling independent instructions behind loads based program provide rather implementation stipulates best case e cache hit balanced scheduling hide variations memory latencies effectively since success depends amount instruction level parallelism code balanced scheduling perform even better parallelism available study combine balanced scheduling three compiler optimizations increase instruction level parallelism loop unrolling trace scheduling cache locality analysis using code generated dec alpha multiflow compiler simulated non blocking processor architecture closely models alpha results show balanced scheduling benefits three optimizations producing average speedups range across optimizations importantly ability tolerate variations load interlocks improves advantage traditional scheduling without optimizations balanced scheduled code average times faster generated traditional scheduler lead increases proceedings acm sigplan conference programming language design implementation la jolla california june pages get postscript file click jlo cs washington edu